{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the paths where all the files are stored\n",
    "current_path = os.getcwd()\n",
    "data_path = current_path + '/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "xtrain = np.load(data_path+'/xtrain0.npy')\n",
    "ytrain = np.load(data_path+'/ytrain0.npy')\n",
    "xval = np.load(data_path+'/xval0.npy')\n",
    "yval = np.load(data_path+'/yval0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical columns\n",
    "ylabel_tr = tf.keras.utils.to_categorical(ytrain, 10)\n",
    "ylabel_val = tf.keras.utils.to_categorical(yval, 10)\n",
    "# Expand dims for the training and validation data\n",
    "xtrain = np.expand_dims(xtrain,axis=-1)\n",
    "xval = np.expand_dims(xval,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38000, 28, 28, 1), (38000, 10), (4000, 28, 28, 1), (4000, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(xtrain), np.shape(ylabel_tr), np.shape(xval), np.shape(ylabel_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of whole datasets (42000, 28, 28, 1) (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load the whole dataset\n",
    "xtrain_wh = np.load(data_path+'/xtrain.npy')\n",
    "ytrain_wh = np.load(data_path+'/ytrain.npy')\n",
    "# Expand dims for the training and validation data\n",
    "xtrain_wh = np.expand_dims(xtrain_wh,axis=-1)\n",
    "# Convert labels to categorical columns\n",
    "ytrain_wh = tf.keras.utils.to_categorical(ytrain_wh, 10)\n",
    "print('shape of whole datasets',np.shape(xtrain_wh), np.shape(ytrain_wh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of whole datasets (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the whole test dataset\n",
    "xtest = np.load(data_path+'/xtest.npy')\n",
    "# Expand dims for the test data\n",
    "xtest = np.expand_dims(xtest,axis=-1)\n",
    "print('shape of whole datasets',np.shape(xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, kernel_list, learn_rate, output_shape):\n",
    "    \"\"\"\n",
    "    Build a convolutional neural network for image classification\n",
    "    \n",
    "    Input Args:\n",
    "    input shape: Shape of the input image provided. The input shape should be 28x28x1\n",
    "    kernel_list: List of kernel level information. Its a list of list containing per \n",
    "                    level number of kernels and the kernel shape of the model.\n",
    "    learn_rate: Learning rate of the optimizer\n",
    "    output_shape: Shape of the final layer of the model. 10 in our case\n",
    "    \n",
    "    Output Args:\n",
    "    model: Tensorflow model which is compiled\n",
    "    \"\"\"\n",
    "    def conv_block(num_kernels, kernel_shape, stride_shape,input_layer, layer_num):\n",
    "        \"\"\"\n",
    "        Create a convolution block which is a convolution layer followed by activation\n",
    "        \n",
    "        Input Args:\n",
    "        num_kernels: Number of kernels in the convolution layer\n",
    "        kernel_shape: Shape of the kernels in the convolution layer\n",
    "        stride_shape: Shape of the strides in the convolution layer\n",
    "        input_layer: Input layer connected to the block\n",
    "        layer_num: Layer number in the model\n",
    "        \n",
    "        Output Args:\n",
    "        out: Output Layer of the convolution block\n",
    "        \"\"\"\n",
    "        conv = layers.Conv2D(num_kernels, \n",
    "                                 kernel_shape, \n",
    "                                 padding='valid', \n",
    "                                 activation='relu',\n",
    "                                 strides=stride_shape,\n",
    "                                 name = 'conv'+str(layer_num))(input_layer)\n",
    "        bn = layers.BatchNormalization(name = 'batchnorm'+str(layer_num))(conv)\n",
    "        out = layers.MaxPool2D(pool_size=(3, 3), \n",
    "                             strides=(1, 1), \n",
    "                             name='maxpool'+str(layer_num),\n",
    "                             padding='same')(bn)\n",
    "        return out\n",
    "    \n",
    "    # Create convolution block\n",
    "    input_layer = layers.Input(shape=input_shape, name='input_layer')\n",
    "    # Connect input image to the first convolution block\n",
    "    x = conv_block(kernel_list[0][0], kernel_list[0][1], kernel_list[0][2],input_layer, 1)\n",
    "    # Connect rest of the block to each other\n",
    "    for i in range(1, len(kernel_list)):\n",
    "        kernel = kernel_list[i]\n",
    "        x = conv_block(kernel[0], kernel[1], kernel[2],x, i+1)\n",
    "    \n",
    "    # Connect Flatten layers and add output layer\n",
    "    flatten = layers.Flatten(name='flatten')(x)\n",
    "    dense1 = layers.Dense(50, name = 'dense1')(flatten)\n",
    "    out_layer = layers.Dense(output_shape, activation='softmax', name = 'dense2')(dense1)\n",
    "    \n",
    "    # Define input and outputs of the model\n",
    "    model = models.Model(input_layer, out_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    adam = optimizers.Adam(lr=learn_rate)\n",
    "    model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and hyperparameters of the model\n",
    "\n",
    "## 99.68 accuracy with current model\n",
    "'''\n",
    "output_shape = len(np.unique(ytrain))\n",
    "input_shape = np.shape(xtrain[0,:,:,:])\n",
    "kernel_list = [[32, (3,3), (1,1)],\n",
    "              [32, (3,3), (1,1)],\n",
    "              [32, (3,3), (1,1)],\n",
    "               [64, (3,3), (1,1)],\n",
    "               [64, (3,3), (2,2)]]\n",
    "learn_rate = 5*10**-4\n",
    "num_iterr = 30\n",
    "batch_size = 32\n",
    "'''\n",
    "\n",
    "output_shape = len(np.unique(ytrain))\n",
    "input_shape = np.shape(xtrain[0,:,:,:])\n",
    "kernel_list = [[32, (3,3), (1,1)],\n",
    "              [32, (3,3), (1,1)],\n",
    "              [32, (3,3), (1,1)],\n",
    "               [64, (3,3), (1,1)],\n",
    "               [64, (3,3), (2,2)],\n",
    "               [128, (3,3), (2,2)]]\n",
    "learn_rate = 1*10**-4\n",
    "num_iterr = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(xtrain, ylabel_tr, xval, ylabel_val, input_shape, kernel_list, learn_rate, output_shape, num_iterr, batch_size=32):\n",
    "    \"\"\"\n",
    "    Function to train model\n",
    "    \n",
    "    Input Args:\n",
    "    xtrain: Input images in numpy format\n",
    "    ylabel_tr: Input image labels\n",
    "    xval: Validation images as numpy format\n",
    "    ylabel_val: Validation image labels\n",
    "    input_shape: Shape of the input image provided. The input shape should be 28x28x1\n",
    "    kernel_list: List of kernel level information. Its a list of list containing per \n",
    "                    level number of kernels and the kernel shape of the model.\n",
    "    learn_rate: Learning rate of the optimizer\n",
    "    output_shape: Shape of the final layer of the model. 10 in our case\n",
    "    num_iterr: Number of epochs for training\n",
    "    batch_size: Number of batches of images per epoch\n",
    "    \n",
    "    Output Args:\n",
    "    models: Weights of the model at each step\n",
    "    loss_list: List of training loss\n",
    "    accuracy_list: List of training accuracy \n",
    "    val_loss_list: List of validation loss\n",
    "    val_acc_list: List of validation accuracy\n",
    "    \"\"\"\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    model_wt_dict = {}\n",
    "    # Initialize the model\n",
    "    model = build_model(input_shape, \n",
    "                        kernel_list, \n",
    "                        learn_rate, \n",
    "                        output_shape)\n",
    "    # Train the model\n",
    "    for i in range(num_iterr):\n",
    "        print('Epoch number:{0}/{1}'.format(i+1, num_iterr))\n",
    "        history = model.fit(xtrain, \n",
    "                            ylabel_tr, \n",
    "                            epochs=1, \n",
    "                            validation_data=(xval, ylabel_val),\n",
    "                            batch_size = batch_size)\n",
    "        # get the training and validation loss and accuracy\n",
    "        train_loss = history.history['loss']\n",
    "        train_acc = history.history['accuracy']\n",
    "        val_loss = history.history['val_loss']\n",
    "        val_acc = history.history['val_accuracy']\n",
    "        # Store all the metrics for training and validation samples\n",
    "        loss_list.append(train_loss)\n",
    "        accuracy_list.append(train_acc)\n",
    "        # Store the model weights, and history\n",
    "        model_weights = model.get_weights() \n",
    "        model_wt_dict[i] = model_weights\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "    return model_wt_dict, loss_list, accuracy_list, val_loss_list, val_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batchnorm1 (BatchNormalizati (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batchnorm2 (BatchNormalizati (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool2 (MaxPooling2D)      (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batchnorm3 (BatchNormalizati (None, 22, 22, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool3 (MaxPooling2D)      (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 20, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batchnorm4 (BatchNormalizati (None, 20, 20, 64)        256       \n",
      "_________________________________________________________________\n",
      "maxpool4 (MaxPooling2D)      (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batchnorm5 (BatchNormalizati (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "maxpool5 (MaxPooling2D)      (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batchnorm6 (BatchNormalizati (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "maxpool6 (MaxPooling2D)      (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 50)                102450    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 252,464\n",
      "Trainable params: 251,760\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch number:1/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 16s 409us/sample - loss: 0.2385 - accuracy: 0.9287 - val_loss: 0.0783 - val_accuracy: 0.9770\n",
      "Epoch number:2/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 373us/sample - loss: 0.0555 - accuracy: 0.9829 - val_loss: 0.0547 - val_accuracy: 0.9850\n",
      "Epoch number:3/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 376us/sample - loss: 0.0397 - accuracy: 0.9867 - val_loss: 0.0509 - val_accuracy: 0.9858\n",
      "Epoch number:4/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 376us/sample - loss: 0.0303 - accuracy: 0.9902 - val_loss: 0.0568 - val_accuracy: 0.9862\n",
      "Epoch number:5/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 371us/sample - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.0561 - val_accuracy: 0.9877\n",
      "Epoch number:6/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 372us/sample - loss: 0.0244 - accuracy: 0.9918 - val_loss: 0.0524 - val_accuracy: 0.9875\n",
      "Epoch number:7/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 371us/sample - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0551 - val_accuracy: 0.9875\n",
      "Epoch number:8/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 374us/sample - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.0509 - val_accuracy: 0.9887\n",
      "Epoch number:9/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 375us/sample - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.0697 - val_accuracy: 0.9827\n",
      "Epoch number:10/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 374us/sample - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.0611 - val_accuracy: 0.9860\n",
      "Epoch number:11/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 377us/sample - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.0605 - val_accuracy: 0.9883\n",
      "Epoch number:12/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 367us/sample - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.0624 - val_accuracy: 0.9877\n",
      "Epoch number:13/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 378us/sample - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0549 - val_accuracy: 0.9883\n",
      "Epoch number:14/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 378us/sample - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.0605 - val_accuracy: 0.9895\n",
      "Epoch number:15/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 387us/sample - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.0545 - val_accuracy: 0.9902\n",
      "Epoch number:16/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 381us/sample - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0530 - val_accuracy: 0.9908\n",
      "Epoch number:17/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 384us/sample - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0523 - val_accuracy: 0.9893\n",
      "Epoch number:18/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 383us/sample - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0733 - val_accuracy: 0.9865\n",
      "Epoch number:19/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 378us/sample - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0885 - val_accuracy: 0.9860\n",
      "Epoch number:20/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 393us/sample - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0535 - val_accuracy: 0.9890\n",
      "Epoch number:21/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 386us/sample - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0433 - val_accuracy: 0.9905\n",
      "Epoch number:22/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 379us/sample - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0757 - val_accuracy: 0.9898\n",
      "Epoch number:23/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 383us/sample - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0547 - val_accuracy: 0.9920\n",
      "Epoch number:24/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 394us/sample - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0582 - val_accuracy: 0.9918\n",
      "Epoch number:25/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 399us/sample - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0783 - val_accuracy: 0.9862\n",
      "Epoch number:26/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 375us/sample - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0556 - val_accuracy: 0.9908\n",
      "Epoch number:27/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 399us/sample - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.0593 - val_accuracy: 0.9895\n",
      "Epoch number:28/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 402us/sample - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0654 - val_accuracy: 0.9883\n",
      "Epoch number:29/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 405us/sample - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0705 - val_accuracy: 0.9872\n",
      "Epoch number:30/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 396us/sample - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0681 - val_accuracy: 0.9895\n",
      "Epoch number:31/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 389us/sample - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0589 - val_accuracy: 0.9898\n",
      "Epoch number:32/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 16s 412us/sample - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0630 - val_accuracy: 0.9902\n",
      "Epoch number:33/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 16s 408us/sample - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0865 - val_accuracy: 0.9872\n",
      "Epoch number:34/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 398us/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0681 - val_accuracy: 0.9910\n",
      "Epoch number:35/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 387us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0644 - val_accuracy: 0.9915\n",
      "Epoch number:36/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 387us/sample - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0669 - val_accuracy: 0.9902\n",
      "Epoch number:37/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 16s 408us/sample - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0732 - val_accuracy: 0.9905\n",
      "Epoch number:38/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 389us/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0572 - val_accuracy: 0.9912\n",
      "Epoch number:39/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 390us/sample - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0700 - val_accuracy: 0.9905\n",
      "Epoch number:40/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 398us/sample - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0684 - val_accuracy: 0.9920\n",
      "Epoch number:41/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 395us/sample - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0739 - val_accuracy: 0.9915\n",
      "Epoch number:42/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 397us/sample - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0750 - val_accuracy: 0.9910\n",
      "Epoch number:43/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 388us/sample - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0749 - val_accuracy: 0.9910\n",
      "Epoch number:44/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 391us/sample - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0747 - val_accuracy: 0.9902\n",
      "Epoch number:45/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 391us/sample - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0840 - val_accuracy: 0.9900\n",
      "Epoch number:46/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 371us/sample - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0705 - val_accuracy: 0.9900\n",
      "Epoch number:47/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 402us/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0938 - val_accuracy: 0.9862\n",
      "Epoch number:48/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 398us/sample - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0663 - val_accuracy: 0.9912\n",
      "Epoch number:49/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 402us/sample - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0738 - val_accuracy: 0.9902\n",
      "Epoch number:50/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 396us/sample - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0689 - val_accuracy: 0.9923\n",
      "Epoch number:51/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 401us/sample - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0763 - val_accuracy: 0.9905\n",
      "Epoch number:52/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 396us/sample - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1263 - val_accuracy: 0.9835\n",
      "Epoch number:53/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 387us/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0695 - val_accuracy: 0.9905\n",
      "Epoch number:54/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 404us/sample - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0807 - val_accuracy: 0.9910\n",
      "Epoch number:55/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 390us/sample - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0835 - val_accuracy: 0.9890\n",
      "Epoch number:56/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 397us/sample - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0782 - val_accuracy: 0.9910\n",
      "Epoch number:57/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 390us/sample - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0718 - val_accuracy: 0.9910\n",
      "Epoch number:58/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 394us/sample - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0836 - val_accuracy: 0.9898\n",
      "Epoch number:59/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 398us/sample - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0756 - val_accuracy: 0.9900\n",
      "Epoch number:60/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 383us/sample - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0882 - val_accuracy: 0.9885\n",
      "Epoch number:61/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 404us/sample - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0915 - val_accuracy: 0.9890\n",
      "Epoch number:62/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 377us/sample - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0828 - val_accuracy: 0.9880\n",
      "Epoch number:63/100\n",
      "Train on 38000 samples, validate on 4000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38000/38000 [==============================] - 15s 390us/sample - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0651 - val_accuracy: 0.9908\n",
      "Epoch number:64/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 404us/sample - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0870 - val_accuracy: 0.9898\n",
      "Epoch number:65/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 384us/sample - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0896 - val_accuracy: 0.9898\n",
      "Epoch number:66/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 392us/sample - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0695 - val_accuracy: 0.9905\n",
      "Epoch number:67/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 385us/sample - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0708 - val_accuracy: 0.9905\n",
      "Epoch number:68/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 394us/sample - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0746 - val_accuracy: 0.9885\n",
      "Epoch number:69/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 385us/sample - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0775 - val_accuracy: 0.9900\n",
      "Epoch number:70/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 395us/sample - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0687 - val_accuracy: 0.9910\n",
      "Epoch number:71/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 395us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0889 - val_accuracy: 0.9902\n",
      "Epoch number:72/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 400us/sample - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0872 - val_accuracy: 0.9920\n",
      "Epoch number:73/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 390us/sample - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0723 - val_accuracy: 0.9905\n",
      "Epoch number:74/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 403us/sample - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0705 - val_accuracy: 0.9925\n",
      "Epoch number:75/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 16s 411us/sample - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0840 - val_accuracy: 0.9912\n",
      "Epoch number:76/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 386us/sample - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0721 - val_accuracy: 0.9918\n",
      "Epoch number:77/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 391us/sample - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0819 - val_accuracy: 0.9918\n",
      "Epoch number:78/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 394us/sample - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0813 - val_accuracy: 0.9912\n",
      "Epoch number:79/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 408us/sample - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0726 - val_accuracy: 0.9920\n",
      "Epoch number:80/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 16s 408us/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0775 - val_accuracy: 0.9908\n",
      "Epoch number:81/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 390us/sample - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0602 - val_accuracy: 0.9927\n",
      "Epoch number:82/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 403us/sample - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0691 - val_accuracy: 0.9902\n",
      "Epoch number:83/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 386us/sample - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0961 - val_accuracy: 0.9910\n",
      "Epoch number:84/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 391us/sample - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0764 - val_accuracy: 0.9915\n",
      "Epoch number:85/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 395us/sample - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0880 - val_accuracy: 0.9905\n",
      "Epoch number:86/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 384us/sample - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0850 - val_accuracy: 0.9900\n",
      "Epoch number:87/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 398us/sample - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0750 - val_accuracy: 0.9905\n",
      "Epoch number:88/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 392us/sample - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0789 - val_accuracy: 0.9920\n",
      "Epoch number:89/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 387us/sample - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0878 - val_accuracy: 0.9905\n",
      "Epoch number:90/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 405us/sample - loss: 9.9877e-04 - accuracy: 0.9998 - val_loss: 0.0899 - val_accuracy: 0.9910\n",
      "Epoch number:91/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 16s 409us/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0899 - val_accuracy: 0.9918\n",
      "Epoch number:92/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 391us/sample - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0917 - val_accuracy: 0.9905\n",
      "Epoch number:93/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 396us/sample - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0804 - val_accuracy: 0.9912\n",
      "Epoch number:94/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 14s 376us/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0869 - val_accuracy: 0.9920\n",
      "Epoch number:95/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 399us/sample - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0720 - val_accuracy: 0.9925\n",
      "Epoch number:96/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 403us/sample - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0665 - val_accuracy: 0.9923\n",
      "Epoch number:97/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 397us/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0909 - val_accuracy: 0.9918\n",
      "Epoch number:98/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 384us/sample - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0798 - val_accuracy: 0.9915\n",
      "Epoch number:99/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 386us/sample - loss: 5.6522e-04 - accuracy: 0.9998 - val_loss: 0.0700 - val_accuracy: 0.9925\n",
      "Epoch number:100/100\n",
      "Train on 38000 samples, validate on 4000 samples\n",
      "38000/38000 [==============================] - 15s 395us/sample - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0712 - val_accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "model_wt_dict, loss_list, accuracy_list, val_loss_list, val_acc_list = train_model(xtrain, \n",
    "                                                                            ylabel_tr,\n",
    "                                                                            xval, \n",
    "                                                                            ylabel_val, \n",
    "                                                                            input_shape, \n",
    "                                                                            kernel_list, \n",
    "                                                                            learn_rate, \n",
    "                                                                            output_shape,\n",
    "                                                                            num_iterr,\n",
    "                                                                            batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_list, label='accuracy')\n",
    "plt.plot(val_acc_list, label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.7, 1])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list, label='loss')\n",
    "plt.plot(val_loss_list, label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is at 20th epoch\n"
     ]
    }
   ],
   "source": [
    "# Find model with the least validation loss\n",
    "index = np.argmin(val_loss_list)\n",
    "# Use that index to retrieve model weights\n",
    "model_wt = model_wt_dict[index]\n",
    "print('Best model is at {0}th epoch'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batchnorm1 (BatchNormalizati (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batchnorm2 (BatchNormalizati (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool2 (MaxPooling2D)      (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batchnorm3 (BatchNormalizati (None, 22, 22, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool3 (MaxPooling2D)      (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 20, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batchnorm4 (BatchNormalizati (None, 20, 20, 64)        256       \n",
      "_________________________________________________________________\n",
      "maxpool4 (MaxPooling2D)      (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batchnorm5 (BatchNormalizati (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "maxpool5 (MaxPooling2D)      (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batchnorm6 (BatchNormalizati (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "maxpool6 (MaxPooling2D)      (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 50)                102450    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 252,464\n",
      "Trainable params: 251,760\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the model with weights\n",
    "model = build_model(input_shape, \n",
    "                        kernel_list, \n",
    "                        learn_rate, \n",
    "                        output_shape)\n",
    "model.set_weights(model_wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 - 1s - loss: 0.0433 - accuracy: 0.9905\n",
      "\n",
      "Test accuracy = 99.05%\n"
     ]
    }
   ],
   "source": [
    "# Test accuray on the validation dataset\n",
    "test_loss, test_accuracy = model.evaluate(xval,  ylabel_val, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy = {0:.2f}%'.format(test_accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 - 8s - loss: 0.0088 - accuracy: 0.9977\n",
      "\n",
      "Train accuracy on whole dataset = 99.77%\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy on the entire dataset\n",
    "train_wh_loss, train_wh_accuracy = model.evaluate(xtrain_wh,  ytrain_wh, verbose=2)\n",
    "\n",
    "print('\\nTrain accuracy on whole dataset = {0:.2f}%'.format(train_wh_accuracy*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if save path exists, if not then create one\n",
    "save_path = current_path + '/model' \n",
    "if not os.path.isdir(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(model, xtest, current_path):\n",
    "    \"\"\"\n",
    "    Create keggale submission csv. This also performs prediction on xtest\n",
    "    \n",
    "    Input Args:\n",
    "    model: Trained model\n",
    "    xtest: Numpy image of the test dataset\n",
    "    current_path: Path where submission file has to be created.\n",
    "                    It takes the previously stored sample submission file which you get \n",
    "                    from kaggle dataset\n",
    "    \"\"\"\n",
    "    # Predict test set labels\n",
    "    ypred = model.predict(xtest)\n",
    "    # Get labels for each row with maximum column value\n",
    "    ytest_label = np.argmax(ypred, axis=1)\n",
    "    # read the sample submission file \n",
    "    samp_submission_df = pd.read_csv(current_path+'/sample_submission.csv')\n",
    "    # add the the new ytest label \n",
    "    samp_submission_df.loc[:,'Label'] = ytest_label\n",
    "    # Save the file as submission \n",
    "    samp_submission_df.to_csv(current_path + '/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model if the accuracy on whole dataset is greater than 99.9 and also create test submission\n",
    "if round(train_wh_accuracy*100.0,3) > 99.9:\n",
    "    filename = save_path + '/model' + str(round(train_wh_accuracy*100.0,3))\n",
    "    model_json = model.to_json()\n",
    "    with open(filename + '.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    # Save weights of the model\n",
    "    model.save_weights(filename+'.h5')\n",
    "    # Create submission\n",
    "    create_submission(model, xtest, current_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
