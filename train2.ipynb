{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New train function that uses whole training data without validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from model_files import model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the paths where all the files are stored\n",
    "current_path = os.getcwd()\n",
    "data_path = current_path + '/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all train data and test data\n",
    "xtr = np.load(data_path+'/xtrain.npy')\n",
    "ytr = np.load(data_path+'/ytrain.npy')\n",
    "xtst = np.load(data_path+'/xtest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical columns\n",
    "ytrain = tf.keras.utils.to_categorical(ytr, len(np.unique(ytr)))\n",
    "# Expand dims for the training and validation data\n",
    "xtrain = np.expand_dims(xtr,axis=-1)\n",
    "xtest = np.expand_dims(xtst,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of whole train datasets (42000, 28, 28, 1)\n",
      "shape of train label datasets (42000, 10)\n",
      "shape of whole test datasets (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print('shape of whole train datasets',np.shape(xtrain))\n",
    "print('shape of train label datasets',np.shape(ytrain))\n",
    "print('shape of whole test datasets',np.shape(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval = []\n",
    "ylabel_val = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and hyperparameters of the model\n",
    "\n",
    "## 99.68 accuracy with current model\n",
    "'''\n",
    "output_shape = len(np.unique(ytrain))\n",
    "input_shape = np.shape(xtrain[0,:,:,:])\n",
    "kernel_list = [[32, (3,3), (1,1)],\n",
    "              [32, (3,3), (1,1)],\n",
    "              [32, (3,3), (1,1)],\n",
    "               [64, (3,3), (1,1)],\n",
    "               [64, (3,3), (2,2)]]\n",
    "learn_rate = 5*10**-4\n",
    "num_iterr = 30\n",
    "batch_size = 32\n",
    "'''\n",
    "\n",
    "output_shape = len(np.unique(ytr))\n",
    "input_shape = np.shape(xtrain[0,:,:,:])\n",
    "kernel_list = [[32, (3,3), (1,1)],\n",
    "              [32, (3,3), (2,2)],\n",
    "              [32, (3,3), (1,1)],\n",
    "               [64, (3,3), (1,1)],\n",
    "               [64, (3,3), (1,1)]]\n",
    "learn_rate = 5*10**-4\n",
    "num_iterr = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(xtrain, ytrain, xval, ylabel_val, input_shape, kernel_list, learn_rate, output_shape, num_iterr, batch_size=32):\n",
    "    \"\"\"\n",
    "    Function to train model\n",
    "    \n",
    "    Input Args:\n",
    "    xtrain: Input images in numpy format\n",
    "    ytrain: Input image labels\n",
    "    xval: Validation images as numpy format\n",
    "    ylabel_val: Validation image labels\n",
    "    input_shape: Shape of the input image provided. The input shape should be 28x28x1\n",
    "    kernel_list: List of kernel level information. Its a list of list containing per \n",
    "                    level number of kernels and the kernel shape of the model.\n",
    "    learn_rate: Learning rate of the optimizer\n",
    "    output_shape: Shape of the final layer of the model. 10 in our case\n",
    "    num_iterr: Number of epochs for training\n",
    "    batch_size: Number of batches of images per epoch\n",
    "    \n",
    "    Output Args:\n",
    "    models: Weights of the model at each step\n",
    "    loss_list: List of training loss\n",
    "    accuracy_list: List of training accuracy \n",
    "    val_loss_list: List of validation loss\n",
    "    val_acc_list: List of validation accuracy\n",
    "    \"\"\"\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    model_wt_dict = {}\n",
    "    # Initialize the model\n",
    "    model = model1(input_shape, \n",
    "                        kernel_list, \n",
    "                        learn_rate, \n",
    "                        output_shape)\n",
    "    # Train the model\n",
    "    for i in range(num_iterr):\n",
    "        print('Epoch number:{0}/{1}'.format(i+1, num_iterr))\n",
    "        # Check validation set is provided\n",
    "        if not xval or not ylabel_val:\n",
    "            history = model.fit(xtrain, \n",
    "                            ytrain, \n",
    "                            epochs=1,\n",
    "                            batch_size = batch_size)\n",
    "            val_loss, val_acc = model.evaluate(xtrain,  \n",
    "                                               ytrain, \n",
    "                                               verbose=2)\n",
    "        else:\n",
    "            history = model.fit(xtrain, \n",
    "                                ytrain, \n",
    "                                epochs=1, \n",
    "                                validation_data=(xval, ylabel_val),\n",
    "                                batch_size = batch_size)\n",
    "            # get the validation loss and accuracy and store it\n",
    "            val_loss = history.history['val_loss']\n",
    "            val_acc = history.history['val_accuracy']\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        # get the training loss and accuracy and store it\n",
    "        train_loss = history.history['loss']\n",
    "        train_acc = history.history['accuracy']\n",
    "        loss_list.append(train_loss)\n",
    "        accuracy_list.append(train_acc)\n",
    "        # Store the model weights, and history\n",
    "        model_weights = model.get_weights() \n",
    "        model_wt_dict[i] = model_weights\n",
    "    return model_wt_dict, loss_list, accuracy_list, val_loss_list, val_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batchnorm1 (BatchNormalizati (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batchnorm2 (BatchNormalizati (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool2 (MaxPooling2D)      (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batchnorm3 (BatchNormalizati (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool3 (MaxPooling2D)      (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batchnorm4 (BatchNormalizati (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "maxpool4 (MaxPooling2D)      (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batchnorm5 (BatchNormalizati (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "maxpool5 (MaxPooling2D)      (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 50)                115250    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 190,896\n",
      "Trainable params: 190,448\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch number:1/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 9s 223us/sample - loss: 0.1863 - accuracy: 0.9501\n",
      "42000/42000 - 4s - loss: 0.0740 - accuracy: 0.9794\n",
      "Epoch number:2/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0877 - accuracy: 0.9780\n",
      "42000/42000 - 3s - loss: 0.0526 - accuracy: 0.9853\n",
      "Epoch number:3/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0652 - accuracy: 0.9835\n",
      "42000/42000 - 4s - loss: 0.0892 - accuracy: 0.9757\n",
      "Epoch number:4/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 185us/sample - loss: 0.0526 - accuracy: 0.9864\n",
      "42000/42000 - 3s - loss: 0.0417 - accuracy: 0.9875\n",
      "Epoch number:5/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 186us/sample - loss: 0.0489 - accuracy: 0.9872\n",
      "42000/42000 - 3s - loss: 0.0543 - accuracy: 0.9839\n",
      "Epoch number:6/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 7s 178us/sample - loss: 0.0409 - accuracy: 0.9891\n",
      "42000/42000 - 4s - loss: 0.0537 - accuracy: 0.9843\n",
      "Epoch number:7/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0280 - accuracy: 0.9918\n",
      "42000/42000 - 4s - loss: 0.0323 - accuracy: 0.9909\n",
      "Epoch number:8/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0328 - accuracy: 0.9916\n",
      "42000/42000 - 3s - loss: 0.0152 - accuracy: 0.9954\n",
      "Epoch number:9/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 184us/sample - loss: 0.0261 - accuracy: 0.9922\n",
      "42000/42000 - 4s - loss: 0.0203 - accuracy: 0.9938\n",
      "Epoch number:10/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0237 - accuracy: 0.9932\n",
      "42000/42000 - 3s - loss: 0.0270 - accuracy: 0.9916\n",
      "Epoch number:11/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 185us/sample - loss: 0.0220 - accuracy: 0.9935\n",
      "42000/42000 - 3s - loss: 0.0176 - accuracy: 0.9946\n",
      "Epoch number:12/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0184 - accuracy: 0.9944\n",
      "42000/42000 - 4s - loss: 0.0143 - accuracy: 0.9957\n",
      "Epoch number:13/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0216 - accuracy: 0.9939\n",
      "42000/42000 - 4s - loss: 0.0131 - accuracy: 0.9956\n",
      "Epoch number:14/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0159 - accuracy: 0.9947\n",
      "42000/42000 - 4s - loss: 0.0314 - accuracy: 0.9911\n",
      "Epoch number:15/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 188us/sample - loss: 0.0163 - accuracy: 0.9951\n",
      "42000/42000 - 3s - loss: 0.0108 - accuracy: 0.9962\n",
      "Epoch number:16/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 185us/sample - loss: 0.0124 - accuracy: 0.9958\n",
      "42000/42000 - 3s - loss: 0.0583 - accuracy: 0.9840\n",
      "Epoch number:17/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0138 - accuracy: 0.9953\n",
      "42000/42000 - 3s - loss: 0.0103 - accuracy: 0.9967\n",
      "Epoch number:18/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0116 - accuracy: 0.9965\n",
      "42000/42000 - 3s - loss: 0.0097 - accuracy: 0.9968\n",
      "Epoch number:19/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 185us/sample - loss: 0.0123 - accuracy: 0.9962\n",
      "42000/42000 - 3s - loss: 0.0113 - accuracy: 0.9962\n",
      "Epoch number:20/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0109 - accuracy: 0.9965\n",
      "42000/42000 - 3s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch number:21/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 186us/sample - loss: 0.0095 - accuracy: 0.9969\n",
      "42000/42000 - 3s - loss: 0.0072 - accuracy: 0.9974\n",
      "Epoch number:22/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 184us/sample - loss: 0.0112 - accuracy: 0.9967\n",
      "42000/42000 - 3s - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch number:23/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 184us/sample - loss: 0.0090 - accuracy: 0.9974\n",
      "42000/42000 - 4s - loss: 0.0058 - accuracy: 0.9982\n",
      "Epoch number:24/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0078 - accuracy: 0.9977\n",
      "42000/42000 - 3s - loss: 0.0083 - accuracy: 0.9970\n",
      "Epoch number:25/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0088 - accuracy: 0.9970\n",
      "42000/42000 - 3s - loss: 0.0188 - accuracy: 0.9943\n",
      "Epoch number:26/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 187us/sample - loss: 0.0078 - accuracy: 0.9977\n",
      "42000/42000 - 3s - loss: 0.0080 - accuracy: 0.9976\n",
      "Epoch number:27/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0074 - accuracy: 0.9978\n",
      "42000/42000 - 4s - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch number:28/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 0.0071 - accuracy: 0.9976\n",
      "42000/42000 - 4s - loss: 0.0107 - accuracy: 0.9967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number:29/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0068 - accuracy: 0.9980\n",
      "42000/42000 - 4s - loss: 0.0044 - accuracy: 0.9982\n",
      "Epoch number:30/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0074 - accuracy: 0.9975\n",
      "42000/42000 - 4s - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch number:31/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0075 - accuracy: 0.9979\n",
      "42000/42000 - 3s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch number:32/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0050 - accuracy: 0.9985\n",
      "42000/42000 - 4s - loss: 0.0060 - accuracy: 0.9979\n",
      "Epoch number:33/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 180us/sample - loss: 0.0067 - accuracy: 0.9980\n",
      "42000/42000 - 4s - loss: 0.0114 - accuracy: 0.9965\n",
      "Epoch number:34/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0051 - accuracy: 0.9984\n",
      "42000/42000 - 4s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch number:35/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0044 - accuracy: 0.9985\n",
      "42000/42000 - 3s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch number:36/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0068 - accuracy: 0.9980\n",
      "42000/42000 - 4s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch number:37/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0045 - accuracy: 0.9985\n",
      "42000/42000 - 4s - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch number:38/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 0.0046 - accuracy: 0.9984\n",
      "42000/42000 - 4s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch number:39/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0048 - accuracy: 0.9984\n",
      "42000/42000 - 4s - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch number:40/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 180us/sample - loss: 0.0042 - accuracy: 0.9987\n",
      "42000/42000 - 4s - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch number:41/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 188us/sample - loss: 0.0056 - accuracy: 0.9983\n",
      "42000/42000 - 4s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch number:42/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0037 - accuracy: 0.9989\n",
      "42000/42000 - 3s - loss: 0.0070 - accuracy: 0.9980\n",
      "Epoch number:43/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0070 - accuracy: 0.9979\n",
      "42000/42000 - 4s - loss: 0.0033 - accuracy: 0.9988\n",
      "Epoch number:44/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 0.0044 - accuracy: 0.9985\n",
      "42000/42000 - 4s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch number:45/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 184us/sample - loss: 0.0033 - accuracy: 0.9990\n",
      "42000/42000 - 4s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch number:46/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0035 - accuracy: 0.9987\n",
      "42000/42000 - 4s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch number:47/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0058 - accuracy: 0.9982\n",
      "42000/42000 - 4s - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch number:48/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0026 - accuracy: 0.9991\n",
      "42000/42000 - 4s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch number:49/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0037 - accuracy: 0.9990\n",
      "42000/42000 - 4s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch number:50/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 0.0062 - accuracy: 0.9982\n",
      "42000/42000 - 4s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch number:51/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 0.0034 - accuracy: 0.9989\n",
      "42000/42000 - 4s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch number:52/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0034 - accuracy: 0.9989\n",
      "42000/42000 - 3s - loss: 0.0057 - accuracy: 0.9978\n",
      "Epoch number:53/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 186us/sample - loss: 0.0047 - accuracy: 0.9985\n",
      "42000/42000 - 4s - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch number:54/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 184us/sample - loss: 0.0021 - accuracy: 0.9993\n",
      "42000/42000 - 4s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch number:55/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 187us/sample - loss: 0.0037 - accuracy: 0.9988\n",
      "42000/42000 - 3s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch number:56/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 187us/sample - loss: 0.0038 - accuracy: 0.9990\n",
      "42000/42000 - 4s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch number:57/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 180us/sample - loss: 0.0043 - accuracy: 0.9987\n",
      "42000/42000 - 3s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch number:58/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 0.0022 - accuracy: 0.9992\n",
      "42000/42000 - 3s - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch number:59/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 180us/sample - loss: 0.0035 - accuracy: 0.9990\n",
      "42000/42000 - 3s - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch number:60/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 180us/sample - loss: 0.0042 - accuracy: 0.9988\n",
      "42000/42000 - 3s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch number:61/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 191us/sample - loss: 0.0020 - accuracy: 0.9994\n",
      "42000/42000 - 4s - loss: 4.5491e-04 - accuracy: 0.9998\n",
      "Epoch number:62/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 185us/sample - loss: 0.0034 - accuracy: 0.9989\n",
      "42000/42000 - 3s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch number:63/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 190us/sample - loss: 0.0041 - accuracy: 0.9986\n",
      "42000/42000 - 4s - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch number:64/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0026 - accuracy: 0.9991\n",
      "42000/42000 - 4s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch number:65/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0028 - accuracy: 0.9992\n",
      "42000/42000 - 4s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch number:66/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 9s 203us/sample - loss: 0.0029 - accuracy: 0.9990\n",
      "42000/42000 - 4s - loss: 9.8946e-04 - accuracy: 0.9996\n",
      "Epoch number:67/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 198us/sample - loss: 0.0028 - accuracy: 0.9992\n",
      "42000/42000 - 4s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch number:68/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 197us/sample - loss: 0.0032 - accuracy: 0.9988\n",
      "42000/42000 - 4s - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch number:69/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 192us/sample - loss: 0.0040 - accuracy: 0.9988\n",
      "42000/42000 - 4s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch number:70/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 196us/sample - loss: 0.0017 - accuracy: 0.9995\n",
      "42000/42000 - 4s - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch number:71/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 187us/sample - loss: 0.0036 - accuracy: 0.9990\n",
      "42000/42000 - 4s - loss: 0.0055 - accuracy: 0.9982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number:72/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 9s 203us/sample - loss: 0.0020 - accuracy: 0.9995\n",
      "42000/42000 - 4s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch number:73/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0038 - accuracy: 0.9990\n",
      "42000/42000 - 3s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch number:74/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 188us/sample - loss: 0.0019 - accuracy: 0.9993\n",
      "42000/42000 - 4s - loss: 0.0035 - accuracy: 0.9992\n",
      "Epoch number:75/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 194us/sample - loss: 0.0036 - accuracy: 0.9991\n",
      "42000/42000 - 4s - loss: 0.0010 - accuracy: 0.9995\n",
      "Epoch number:76/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 9s 203us/sample - loss: 0.0030 - accuracy: 0.9990\n",
      "42000/42000 - 4s - loss: 6.1068e-04 - accuracy: 0.9998\n",
      "Epoch number:77/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 199us/sample - loss: 0.0028 - accuracy: 0.9993\n",
      "42000/42000 - 4s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch number:78/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 191us/sample - loss: 0.0025 - accuracy: 0.9992\n",
      "42000/42000 - 3s - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch number:79/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0037 - accuracy: 0.9989\n",
      "42000/42000 - 3s - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch number:80/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0011 - accuracy: 0.9996\n",
      "42000/42000 - 4s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch number:81/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0024 - accuracy: 0.9993\n",
      "42000/42000 - 3s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch number:82/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0017 - accuracy: 0.9995\n",
      "42000/42000 - 3s - loss: 7.0972e-04 - accuracy: 0.9998\n",
      "Epoch number:83/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0036 - accuracy: 0.9989\n",
      "42000/42000 - 3s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch number:84/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0026 - accuracy: 0.9993\n",
      "42000/42000 - 4s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch number:85/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0023 - accuracy: 0.9994\n",
      "42000/42000 - 3s - loss: 0.0026 - accuracy: 0.9989\n",
      "Epoch number:86/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0021 - accuracy: 0.9994\n",
      "42000/42000 - 3s - loss: 6.3773e-04 - accuracy: 0.9998\n",
      "Epoch number:87/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0034 - accuracy: 0.9990\n",
      "42000/42000 - 4s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch number:88/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 180us/sample - loss: 9.8206e-04 - accuracy: 0.9997\n",
      "42000/42000 - 3s - loss: 8.9194e-05 - accuracy: 1.0000\n",
      "Epoch number:89/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0038 - accuracy: 0.9990\n",
      "42000/42000 - 3s - loss: 0.0106 - accuracy: 0.9973\n",
      "Epoch number:90/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0018 - accuracy: 0.9995\n",
      "42000/42000 - 3s - loss: 7.9932e-04 - accuracy: 0.9998\n",
      "Epoch number:91/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 180us/sample - loss: 0.0032 - accuracy: 0.9992\n",
      "42000/42000 - 3s - loss: 8.5495e-04 - accuracy: 0.9997\n",
      "Epoch number:92/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0011 - accuracy: 0.9998\n",
      "42000/42000 - 4s - loss: 2.3355e-04 - accuracy: 0.9999\n",
      "Epoch number:93/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 194us/sample - loss: 0.0033 - accuracy: 0.9990\n",
      "42000/42000 - 3s - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch number:94/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 180us/sample - loss: 0.0018 - accuracy: 0.9994\n",
      "42000/42000 - 4s - loss: 3.3495e-04 - accuracy: 0.9999\n",
      "Epoch number:95/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 179us/sample - loss: 0.0026 - accuracy: 0.9992\n",
      "42000/42000 - 4s - loss: 6.3296e-04 - accuracy: 0.9998\n",
      "Epoch number:96/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 182us/sample - loss: 0.0012 - accuracy: 0.9995\n",
      "42000/42000 - 3s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch number:97/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 183us/sample - loss: 0.0027 - accuracy: 0.9993\n",
      "42000/42000 - 4s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch number:98/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 181us/sample - loss: 0.0018 - accuracy: 0.9996\n",
      "42000/42000 - 4s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch number:99/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 184us/sample - loss: 0.0021 - accuracy: 0.9993\n",
      "42000/42000 - 4s - loss: 2.3661e-04 - accuracy: 0.9999\n",
      "Epoch number:100/100\n",
      "Train on 42000 samples\n",
      "42000/42000 [==============================] - 8s 187us/sample - loss: 0.0023 - accuracy: 0.9994\n",
      "42000/42000 - 4s - loss: 0.0026 - accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "model_wt_dict, loss_list, accuracy_list, val_loss_list, val_acc_list = train_model(xtrain, \n",
    "                                                                            ytrain,\n",
    "                                                                            xval,  \n",
    "                                                                            ylabel_val, \n",
    "                                                                            input_shape, \n",
    "                                                                            kernel_list, \n",
    "                                                                            learn_rate, \n",
    "                                                                            output_shape,\n",
    "                                                                            num_iterr,\n",
    "                                                                            batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3dfZyVdZ3/8dfn3Mw9NzMwcjsIFso9IiOitmqShaWitoiumZJmbmmlW666bZrZbluWprkmtd6VRUapZKWpYNTPO4YkFBBFRBluBxgGBubmzDmf3x/nmvEAF3DAOQzMvJ+Px3nMue4/11xw3nPdnO/X3B0REZFdRTq6ABEROTQpIEREJJQCQkREQikgREQklAJCRERCKSBERCRUzgLCzO43sw1m9voeppuZ3WVmy81skZkdlzHtUjN7K3hdmqsaRURkz3J5BvEgMHkv088EhgavK4F7AcysDLgZOAGYANxsZqU5rFNERELkLCDcfR6weS+zTAEe9rSXgJ5m1g/4BPCMu29291rgGfYeNCIikgOxDtz2AGBVxnB1MG5P43djZleSPvuguLh4/LBhw3JTaWfiKbB9/F3gDmbZrS+ZgJYGiBdDJLrztFQSkk3peZLNgEEk1vZKEKMpCQ7kxSLkRSOYQUvKaUkksKatRBL1xBLbsFRLep0WhUgUjxXQEsmnxfIwAwMiOHgS8yR4CsdIYqQ8QsScKI6Zk7Q8mqyABvLIizjFkQR53gSJRjyxA2tpIl1VWovFaYqWkIiV4PFCYrEYebEotDSR3LGFeKKOWKqZlEVJEQUzot5CxJPp9ZiRshgtxGiMltAQ7UZLJI8CmilK1RNv2Y57CndPv4ikj1EkgrkDjnmKqLcQ9RbASVqcumgptXTD3ShhO919G3FvJkKKSLBM5n60HV6MZCSfZDQftxiRZCPRVFOw7r0xkkRIRPJpjhSQjBYQ8wR5yQbiqcZge+ktNhFnhxXTFCsm6i0UJbdR7DuIkNr5nwhRWiyKAzFPESW5W82O0Wj5NJNHhPQ80dZ9xDEgQYxGj9HsMSKkiFuSOEnySBCjZad1JS2OkSLaenwwmonRGKy/iKbd6txVHSVsiR0B0Rj5LdvoldxInMRef3eNlk8iUkA81Ui+N2Ehx+ZApIjQECmiuO/QA1p+wYIFG929PGxaRwbEB+buM4AZAJWVlV5VVdXBFXUgd0i1pD+UPQmxQogEQdBUD39/CF68B7auwXt9iKZeI9jRYyjR0kFEyypINTfRsOSPFL/7HEUN61hVNIJFBZUsyD+B+MBjGda3OxVlRby3eQfr33uLcW/fw9CGRZQn1wPQaPm8XPIxXik9m+71Kxi/9VmObVlIbB//0bZ5IYt9MH9InsBTyQmURJr5bORPXBB9nmJrYrOXMC91PItTgymkmW62gyNsC0dbNR+y1eRZw27r3OpF1FNEAc0U00i+tZB0YwcFpIjQw7YB23Zbbq2XsSQ1kqU+iC1eQr61UJYPw1jBcclFFFIL1O60TMqNRZExrCoaQX6ynuLkVlKJJqpberCBntR7IWW2jd7UcXR0LWPtLaCBWrpRGtSwKHUUtd6NvHicovwYlmwimthBLNlAwmIkgg+WGnqyKlnGmpZunB17heNtKXWR9Idat9Q2NkXKWBQZTl2ygK3JPLZHikkVH0G0ez8i8Xyatm4iuWMzJY3rOMpXcUxkFb3YynI/ipWxIWwqPJJEtJhkrIBUJI9UKkWqJYGlmimhgW7soKfXUdH0FkNaVhBnKwBvpQbwaurDtOT3pKw4j15FUfpte53+25cQCX5f26I9WVZ6LusLP8T2xgT1jU3kJXdQbnX0oo4YSeoiPai1HmzxbmyzYrZRRJ4nGOHLOaZlGb1b1tIQKWF7tDvbrZj6VB71yRiJFAyObmKgr6N7YgPN0WK2x0upi5axJX8AW4oHU184kMT2WuJb36OkoZqEFbA9/wiaio6gF9sY0LyCvg3LSUQLWV0yilVFI9lovWhqqKe5cTtmRlFpX8p69eGoTX9h9Ds/o5EdvBMZxOjkGtYWDOfFgVewLRmnuXEHqWSC7t17UtqzlB75hr33Ar02vERF05u8Fx/FO90q2dirku0U0tDURHNzMz1iCcrjTZTFmkilUmxPODsSEI863eJGSdxpjhax0buzIdWDWHIH/ZrfpU/ze+SVlDHmku/txwfG+8zs3T1Oy2VbTGY2GHjS3UeFTLsPeN7dfxUMLwNOa325+xfC5tuTQy4g3NOvSJZX8RpqYe0/0n/hR2KQ3x36jd35L/lkC7z0vySHn8OqVDlvbainIB6homchgx6fQmT1+/ufIMbm2BFsyevLwMa3KE5t47X4aOanhtM/sZLhrOTIyIadS/A8/pYazQr6c3L0DUawnAjOE6mPcEvzZ6ilO/8UWcRd8XvItxZezR/P8vxRrM+roHL7Xzi54XnyaQagJtaP18s+xvL4MN5u6s4bO7qRF4GK/AYG5G1ncEE9g/Pq6Mdmeqx/kaItb5IiguGkLMraik+xefgltPQbR35enJaks3pLA6trG9jWmKBfz0IqesTowxaaUtDQEmFHKkIiWgKRKJEI9CjMo6w4j255sLUxxYb6ZjZvb6aPbWFI8zJ61r1BHd1YnBrIS9uOIFlQyqCyIipKi6goK6Rfj0LyYsHxSzSSWvkC29e/xZa6rdTXb6U5v5TyyvPoN2AwlnGc3J31W5tYvKaO9VubGNK7mKP7lNCrJB+2roGlT0L1fJIVJ1DTfxKbImUMKiuiW0F8l39CvtN62/4ZpJyIgb37Arz0vxCNw9h/gQ+dDtHs/uZLJFNsa2whkUzRqziPWHQ/rza3NEHNMuhZAYWl4bXu2Azv/AWKesGRJ+9+hpkLqVT2/+c+iI1vwZPXwrpF8NFvQOXnsv7dH2rMbIG7V4ZO68CA+BRwNfBJ0jek73L3CcFN6gVA61NNfwfGu/ve7mccWgGRSsETX4I3noSR58GxF0PFhN0v29RvgJd/gr89F9YubDtFb1U76jL++uHrWb6hnnVbG/n4u7fzsW2zeTx1Cl9tvqptvhG2kj/m38QTyZNYlqqgV7cC+uY10r1pLb0S69hgvflDyadZ1300vYrz6NezkP49CugeT2Fb1xLdVk2UFEUfPpkh/XozoGchkYjB9k3wyn34X39IKq+E9QPOoN/bv4HyYdi0X0DvD++8Pzs2w9LfQ/mw8P3dmw1LYfHj6Usr4y+Fbn3397cucvAlWw7bYGjVIQFhZr8ifTbQG1hP+smkOIC7/8TSf278mPQN6B3AdHevCpb9HHBTsKrvuPsD+9reIRMQ7vCH66DqfhhyClRXQWIH9D6GxpOuY37xaSxdv53S9/7Mme/8N4XJbfyDocxrGcn81DE0eh5xSzI58gqXxf7M3S3nckfyAv616Dm+nvw/tkW6k0cLT358Hkf1701TS4oeL/w3xyy/nycmzWHimGPo16Owffdpw1KYfQ1Uz4cx0+CsOyCvuH23ISIdosPOIA6mQyEg3lhbR/LPNzPynQdYccyVLB5xLavXbaDHu39k4vpfMyS5krdSA3jDKzg7+hLL7CjuKb2ekopRjOzfnQ+Vl7CtsYX1WxuprW/irFX/w5B3Z5EcdQHRxbPg6DPh+M/BLz4NFzwMI6akA+nu8elT/c8+kbudSyVh45vps4P9OTOQLiuRSFBdXU1jY2NHlyJAQUEBAwcOJB7f+VLm3gLi8D43OkTUN7Xwwz+/SeTle/hG7Bc83HIG3/zHqfCPVwHo2/0E/tj3o1xQspDT1/0fH976Cv6Rr3HMqf/OXbG8Pa84NQN+50RffxT6jobzZ0CsAIrL4bVZ6YBY/zpsfhtOuia3OxmJwhHDc7sN6VSqq6vp1q0bgwcPDr2XIgePu7Np0yaqq6sZMmRI1sspID6ARDLFk4vW8D9/WkZx/ds8nf9rdgyZzCln/ow/JFJEI8agsiKK8lp/zSdC6gvpS075JfveQCQK590HR54Ew85+f5mR58GCh6Bxa3DdPgrDz87ZfoociMbGRoXDIcLM6NWrFzU1Nfu1nAIiW5tXQF4JlBxB3Y4Ev1mwivv/9g5r6hoZ2beEX/ecSWxrMbHz72ZwSbc9rycSyS4cWkXjcPwVO48b9c/wygx44w+w5HEY/BEo7n1g+yWSQwqHQ8eBHAsFRBZSiWaaf/IxEskkN+TdyB9qKwA4YUgZ3z53FB+te5zIUwvg3J9AyRG5L6hiAvQYBPO+lw6uE7+U+22KSJej1lwzJRPwzDdhzcK2Uau3NPDDn9xLQfMmPJngzsZv8JNx7zL76pP59RdOZFK/JiJzboUPTYKxFx6cOs1g1PnpcLBI+vKTiEg7U0Bk+sv/wP/7Efzp3wF4/NXVTL5jHiM2/onGeE+6XbeA+MDxTF56I2Oe+me4czTcdVz6SaKz7zy4T/eM+nT65+CPQEnot+RF5CBpadlXMyWHJwVEq5V/g3m3Q48KWPUSf3/hWa59dCHj+kSYHHuVgmP/GeveL/0o6YQrIZoHFRPTl3c++zj0HHRw6+07Gk68Gk75+sHdrshh5txzz2X8+PGMHDmSGTNmAPDUU09x3HHHMXbsWCZNmgRAfX0906dPZ/To0YwZM4bf/va3AJSUvH/PcNasWVx22WUAXHbZZVx11VWccMIJXH/99bzyyiuceOKJjBs3jpNOOolly5YBkEwm+drXvsaoUaMYM2YMd999N3PmzOHcc89tW+8zzzzDeeeddzB+HftF9yAg3czF766EsqNg+h9J3V3Jhj//kGP63MDPJrxL5MnG9BfEAOIF8Mnvd2y9kD5b+cR3OroKkax86/eLWbJma7uuc0T/7tx89sh9znf//fdTVlZGQ0MDxx9/PFOmTOHzn/888+bNY8iQIWzenG6k4dvf/jY9evTgtddeA6C2tnZvqwXSj/K+8MILRKNRtm7dyl//+ldisRjPPvssN910E7/97W+ZMWMGK1euZOHChcRiMTZv3kxpaSlf/OIXqampoby8nAceeIDPfe5zH+wXkgMKCHf4/Vegfj1c/gzNhUfwp+jH+JQ/wfBz+pD319uhdDAMPL6jKxWRA3DXXXfx2GOPAbBq1SpmzJjBKaec0vZ9gLKyMgCeffZZZs6c2bZcaem+u6GZOnUq0Wi6jam6ujouvfRS3nrrLcyMRCLRtt6rrrqKWCy20/YuueQSfvGLXzB9+nRefPFFHn744Xba4/ajgNi0HN78M5z+nzDgOL77+yU8XXsa5xQ8wZGv3g7vzINTr9e3h0U+gGz+0s+F559/nmeffZYXX3yRoqIiTjvtNI499ljeeOONrNeR+Xjort8KLy5+v8mZ//zP/+SjH/0ojz32GCtXruS0007b63qnT5/O2WefTUFBAVOnTm0LkEOJ7kH0HgpffAFO+jLbm1p44IV3+Kfjj8NGToHXHgUcRl/Q0VWKyAGoq6ujtLSUoqIi3njjDV566SUaGxuZN28e77zzDkDbJaYzzjiDe+65p23Z1ktMffr0YenSpaRSqbYzkT1ta8CAdNc1Dz74YNv4M844g/vuu6/tRnbr9vr370///v257bbbmD59evvtdDtSQED63kMkwoqa7bjDqUeXw8TguwUDxu/eaqmIHBYmT55MS0sLw4cP54YbbmDixImUl5czY8YMzj//fMaOHcu0aen7i9/4xjeora1l1KhRjB07lrlz5wLw3e9+l7POOouTTjqJfv367XFb119/PTfeeCPjxo3b6ammK664gkGDBjFmzBjGjh3LL3/5y7ZpF198MRUVFQwffmg2Y6PG+jI8sXA1X5m5kKe/egrH9O0Gz34r/Rjphye1U5UiXcfSpUsP2Q++Q8XVV1/NuHHjuPzyyw/K9sKOiRrry9LbNdsxgyN7FaVHfOzmji1IRDqt8ePHU1xczA9+8IOOLmWPFBAZVtTUM7C0kIL4Qej5SkS6tAULFnR0CfukexAZVtRs56je+9GQnohIJ6aACKRSzjsbt3NUuXpKExEBBUSbdVsbaUgkOapcZxAiIqCAaLOiZjsAH+qtMwgREVBAtFmxsR5AZxAiIgEFRGBFzXaK86L06Z7f0aWISAfJbLlVFBBt3q6pZ0h5sbpIFJEOd6j0L6HvQQRW1Gxn/JH7br1RRA7An26Ada+17zr7joYzv7vXWW644QYqKir40pfSTefccsstxGIx5s6dS21tLYlEgttuu40pU6bsc3P19fVMmTIldLmHH36Y22+/HTNjzJgx/PznP2f9+vVcddVVrFixAoB7772X/v37c9ZZZ/H6668DcPvtt1NfX88tt9zS1pDg3/72Ny666CKOPvpobrvtNpqbm+nVqxePPPIIffr0ob6+nmuuuYaqqirMjJtvvpm6ujoWLVrEnXfeCcBPf/pTlixZwh133HHAv15QQADQmEiypq6BqeUDO7oUEWlH06ZN46tf/WpbQDz66KM8/fTTfPnLX6Z79+5s3LiRiRMncs455+zz6kFBQQGPPfbYbsstWbKE2267jRdeeIHevXu3Ncb35S9/mVNPPZXHHnuMZDJJfX39PvuYaG5uprXJoNraWl566SXMjJ/97Gd873vf4wc/+EFovxXxeJzvfOc7fP/73ycej/PAAw9w3333fdBfnwIC4J2N6Ub6dINaJEf28Zd+rowbN44NGzawZs0aampqKC0tpW/fvlx77bXMmzePSCTC6tWrWb9+PX379t3rutydm266abfl5syZw9SpU+nduzfwfn8Pc+bMaevjIRqN0qNHj30GRGvDgZDujGjatGmsXbuW5ubmtv4r9tRvxemnn86TTz7J8OHDSSQSjB49ej9/W7tTQPD+I65H6RFXkU5n6tSpzJo1i3Xr1jFt2jQeeeQRampqWLBgAfF4nMGDB+/Wz0OYA10uUywWI5VKtQ3vrX+Ja665huuuu45zzjmH559/nltuuWWv677iiiv4r//6L4YNG9ZuzYfrJjXpNpgAfYtapBOaNm0aM2fOZNasWUydOpW6ujqOOOII4vE4c+fO5d13381qPXta7vTTT+c3v/kNmzZtAt7v72HSpEnce++9QLpf6rq6Ovr06cOGDRvYtGkTTU1NPPnkk3vdXmv/Eg899FDb+D31W3HCCSewatUqfvnLX3LRRRdl++vZq5wGhJlNNrNlZrbczG4ImX6kmT1nZovM7HkzG5gxLWlmC4PX7FzWuWLjdvr1KKAoTydUIp3NyJEj2bZtGwMGDKBfv35cfPHFVFVVMXr0aB5++GGGDRuW1Xr2tNzIkSP5j//4D0499VTGjh3LddddB8CPfvQj5s6dy+jRoxk/fjxLliwhHo/zzW9+kwkTJnDGGWfsddu33HILU6dOZfz48W2Xr2DP/VYAXHDBBZx88slZdZeajZz1B2FmUeBN4AygGpgPXOTuSzLm+Q3wpLs/ZGanA9Pd/ZJgWr27Z31T4IP0BzHlx3+jpCDGI1dMPKDlRWR36g/i4DvrrLO49tprmTQpvA+b/e0PIpdnEBOA5e6+wt2bgZnArs+SjQDmBO/nhkzPOXdXK64icljbsmULRx99NIWFhXsMhwORy2sqA4BVGcPVwAm7zPMP4HzgR8B5QDcz6+Xum4ACM6sCWoDvuvvjuSiypr6JbU0tuv8gIgC89tprXHLJJTuNy8/P5+WXX+6givatZ8+evPnmm+2+3o6+6P414MdmdhkwD1gNJINpR7r7ajM7CphjZq+5+9uZC5vZlcCVAIMGDTqgAroXxJl55UQGlRUd4C6IyJ64+2HXOsHo0aNZuHBhR5fR7g7kdkIuLzGtBioyhgcG49q4+xp3P9/dxwH/EYzbEvxcHfxcATwPjNt1A+4+w90r3b2yvLz8gIosiEeZeFQv+vcsPKDlRSRcQUEBmzZtOqAPJmlf7s6mTZsoKCjYr+VyeQYxHxhqZkNIB8OFwL9kzmBmvYHN7p4CbgTuD8aXAjvcvSmY52TgezmsVUTa2cCBA6murqampqajSxHSgT1w4P61FpGzgHD3FjO7GngaiAL3u/tiM7sVqHL32cBpwH+bmZO+xPSlYPHhwH1mliJ9lvPdzKefROTQF4/H2779K4ennD3merB9kMdcRUS6qo56zFVERA5jCggREQmlgBARkVAKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCZXTgDCzyWa2zMyWm9kNIdOPNLPnzGyRmT1vZgMzpl1qZm8Fr0tzWaeIiOwuZwFhZlHgHuBMYARwkZmN2GW224GH3X0McCvw38GyZcDNwAnABOBmMyvNVa0iIrK7XJ5BTACWu/sKd28GZgJTdplnBDAneD83Y/ongGfcfbO71wLPAJNzWKuIiOwilwExAFiVMVwdjMv0D+D84P15QDcz65XlspjZlWZWZWZVNTU17Va4iIh0/E3qrwGnmtmrwKnAaiCZ7cLuPsPdK929sry8PFc1ioh0SbEcrns1UJExPDAY18bd1xCcQZhZCfBpd99iZquB03ZZ9vkc1ioiIrvI5RnEfGComQ0xszzgQmB25gxm1tvMWmu4Ebg/eP808HEzKw1uTn88GCciIgdJzgLC3VuAq0l/sC8FHnX3xWZ2q5mdE8x2GrDMzN4E+gDfCZbdDHybdMjMB24NxomIyEFi7t7RNbSLyspKr6qq6ugyREQOK2a2wN0rw6Z19E1qERE5RCkgREQklAJCRERCKSBERCSUAkJEREIpIEREJJQCQkREQikgREQklAJCRERCKSBERCTUPgPCzM7OaFBPRES6iGw++KcBb5nZ98xsWK4LEhGRQ8M+A8LdPwOMA94GHjSzF4Oe3LrlvDoREekwWV06cvetwCzS/Ur3I9096N/N7Joc1iYiIh0om3sQ55jZY6R7dIsDE9z9TGAs8G+5LU9ERDpKNl2Ofhq4w93nZY509x1mdnluyhIRkY6WTUDcAqxtHTCzQqCPu6909+dyVZiIiHSsbO5B/AZIZQwng3EiItKJZRMQMXdvbh0I3uflriQRETkUZBMQNWZ2TuuAmU0BNuauJBERORRkcw/iKuARM/sxYMAq4LM5rUpERDrcPgPC3d8GJppZSTBcn/OqRESkw2VzBoGZfQoYCRSYGQDufmsO6xIRkQ6WzRflfkK6PaZrSF9imgocmeO6RESkg2Vzk/okd/8sUOvu3wJOBI7ObVkiItLRsgmIxuDnDjPrDyRIt8ckIiKdWDb3IH5vZj2B7wN/Bxz4aU6rEhGRDrfXM4igo6Dn3H2Lu/+W9L2HYe7+zWxWbmaTzWyZmS03sxtCpg8ys7lm9qqZLTKzTwbjB5tZg5ktDF4/OYB9ExGRD2CvZxDunjKze0j3B4G7NwFN2azYzKLAPcAZQDUw38xmu/uSjNm+ATzq7vea2Qjgj8DgYNrb7n7s/uyMiIi0n2zuQTxnZp+21udbszcBWO7uK4LmOWYCU3aZx4HuwfsewJr93IaIiORINgHxBdKN8zWZ2VYz22ZmW7NYbgDpb123qg7GZboF+IyZVZM+e8jsgGhIcOnpL2b2T2EbCHq2qzKzqpqamixKEhGRbGXT5Wg3d4+4e567dw+Gu+9ruSxdBDzo7gOBTwI/D+57rAUGufs44Drgl2a22zbdfYa7V7p7ZXl5eTuVJCIikMVTTGZ2Stj4XTsQCrEaqMgYHhiMy3Q5MDlY34tmVgD0dvcNBPc63H2Bmb1N+rsXVfuqV0RE2kc2j7l+PeN9Ael7CwuA0/ex3HxgqJkNIR0MFwL/sss87wGTgAfNbHiw/hozKwc2u3vSzI4ChgIrsqhVRETaSTaN9Z2dOWxmFcCdWSzXYmZXA08DUeB+d19sZrcCVe4+m3Sf1j81s2tJ37C+zN09OGu51cwSpDsrusrdN+/vzomIyIEzd9+/BdJPMy129xG5KenAVFZWelWVrkCJiOwPM1vg7pVh07K5B3E36b/uIX1T+1jS36gWEZFOLJt7EJl/lrcAv3L3/5ejekRE5BCRTUDMAhrdPQnpb0ibWZG778htaSIi0pGy+iY1UJgxXAg8m5tyRETkUJFNQBRkdjMavC/KXUkiInIoyCYgtpvZca0DZjYeaMhdSSIicijI5h7EV4HfmNka0l2O9iXdBamIiHRi2XxRbr6ZDQOOCUYtc/dEbssSEZGOts9LTGb2JaDY3V9399eBEjP7Yu5LExGRjpTNPYjPu/uW1gF3rwU+n7uSRETkUJBNQEQzOwsKeorLy11JIiJyKMjmJvVTwK/N7L5g+AvAn3JXkoiIHAqyCYh/B64ErgqGF5F+kklERDqxbHqUSwEvAytJ9wVxOrA0t2WJiEhH2+MZhJkdTbpL0IuAjcCvAdz9owenNBER6Uh7u8T0BvBX4Cx3Xw4QdOwjIiJdwN4uMZ0PrAXmmtlPzWwS6W9Si4hIF7DHgHD3x939QmAYMJd0kxtHmNm9Zvbxg1WgiIh0jGxuUm93918GfVMPBF4l/WSTiIh0Ytl8Ua6Nu9e6+wx3n5SrgkRE5NCwXwEhIiJdhwJCRERCKSBERCSUAkJEREIpIEREJJQCQkREQikgREQkVE4Dwswmm9kyM1tuZjeETB9kZnPN7FUzW2Rmn8yYdmOw3DIz+0Qu6xQRkd1l0x/EAQl6nrsHOAOoBuab2Wx3X5Ix2zeAR939XjMbAfwRGBy8vxAYCfQHnjWzo909mat6RURkZ7k8g5gALHf3Fe7eDMwEpuwyjwPdg/c9gDXB+ynATHdvcvd3gOXB+kRE5CDJZUAMAFZlDFcH4zLdAnzGzKpJnz1csx/LYmZXmlmVmVXV1NS0V90iIkLH36S+CHjQ3QcCnwR+bmZZ1xS0C1Xp7pXl5eU5K1JEpCvK2T0IYDVQkTE8MBiX6XJgMoC7v2hmBUDvLJcVEZEcyuUZxHxgqJkNMbM80jedZ+8yz3vAJAAzGw4UADXBfBeaWb6ZDQGGAq/ksFYREdlFzs4g3L3FzK4GngaiwP3uvtjMbgWq3H028G/AT4OuTFrcq6QAAAk5SURBVB24zN0dWGxmjwJLgBbgS3qCSUTk4LL05/Hhr7Ky0quqqjq6DBGRw4qZLXD3yrBpHX2TWkREDlEKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCaWAEBGRUDkNCDObbGbLzGy5md0QMv0OM1sYvN40sy0Z05IZ02bnsk4REdldLFcrNrMocA9wBlANzDez2e6+pHUed782Y/5rgHEZq2hw92NzVZ+IiOxdLs8gJgDL3X2FuzcDM4Epe5n/IuBXOaxHRET2Qy4DYgCwKmO4Ohi3GzM7EhgCzMkYXWBmVWb2kpmdm7syRUQkTM4uMe2nC4FZ7p7MGHeku682s6OAOWb2mru/nbmQmV0JXAkwaNCgg1etiEgXkMsziNVARcbwwGBcmAvZ5fKSu68Ofq4Anmfn+xOt88xw90p3rywvL2+PmkVEJJDLgJgPDDWzIWaWRzoEdnsaycyGAaXAixnjSs0sP3jfGzgZWLLrsiIikjs5u8Tk7i1mdjXwNBAF7nf3xWZ2K1Dl7q1hcSEw0909Y/HhwH1mliIdYt/NfPpJRERyz3b+XD58VVZWelVVVUeXISJyWDGzBe5eGTZN36QWEZFQCggREQmlgBARkVAKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCaWAEBGRUAoIEREJpYAQEZFQCggREQmlgBARkVAKCBERCZXTgDCzyWa2zMyWm9kNIdPvMLOFwetNM9uSMe1SM3sreF2ayzpFRGR3sVyt2MyiwD3AGUA1MN/MZrv7ktZ53P3ajPmvAcYF78uAm4FKwIEFwbK1uapXRER2lssziAnAcndf4e7NwExgyl7mvwj4VfD+E8Az7r45CIVngMk5rFVERHaRszMIYACwKmO4GjghbEYzOxIYAszZy7IDQpa7ErgyGKw3s2UfoN7ewMYPsPzhqCvuM3TN/e6K+wxdc7/3d5+P3NOEXAbE/rgQmOXuyf1ZyN1nADPaowAzq3L3yvZY1+GiK+4zdM397or7DF1zv9tzn3N5iWk1UJExPDAYF+ZC3r+8tL/LiohIDuQyIOYDQ81siJnlkQ6B2bvOZGbDgFLgxYzRTwMfN7NSMysFPh6MExGRgyRnl5jcvcXMrib9wR4F7nf3xWZ2K1Dl7q1hcSEw0909Y9nNZvZt0iEDcKu7b85VrYF2uVR1mOmK+wxdc7+74j5D19zvdttny/hcFhERaaNvUouISCgFhIiIhOryAbGv5kA6CzOrMLO5ZrbEzBab2VeC8WVm9kzQpMkzwUMBnYqZRc3sVTN7MhgeYmYvB8f818FDFJ2KmfU0s1lm9oaZLTWzEzv7sTaza4N/26+b2a/MrKAzHmszu9/MNpjZ6xnjQo+tpd0V7P8iMztuf7bVpQMiozmQM4ERwEVmNqJjq8qZFuDf3H0EMBH4UrCvNwDPuftQ4LlguLP5CrA0Y/h/gDvc/cNALXB5h1SVWz8CnnL3YcBY0vvfaY+1mQ0AvgxUuvso0g/GXEjnPNYPsnvLEns6tmcCQ4PXlcC9+7OhLh0Q7H9zIIctd1/r7n8P3m8j/YExgPT+PhTM9hBwbsdUmBtmNhD4FPCzYNiA04FZwSydcZ97AKcA/wfg7s3uvoVOfqxJP5VZaGYxoAhYSyc81u4+D9j1qc49HdspwMOe9hLQ08z6Zbutrh4QWTXp0dmY2WDSDSO+DPRx97XBpHVAnw4qK1fuBK4HUsFwL2CLu7cEw53xmA8BaoAHgktrPzOzYjrxsXb31cDtwHukg6EOWEDnP9at9nRsP9BnXFcPiC7HzEqA3wJfdfetmdOC76J0mueezewsYIO7L+joWg6yGHAccK+7jwO2s8vlpE54rEtJ/7U8BOgPFNNFG/hsz2Pb1QOiSzXpYWZx0uHwiLv/Lhi9vvWUM/i5oaPqy4GTgXPMbCXpy4enk7423zO4DAGd85hXA9Xu/nIwPIt0YHTmY/0x4B13r3H3BPA70se/sx/rVns6th/oM66rB0RWzYF0BsG19/8Dlrr7DzMmzQZaO2S6FHjiYNeWK+5+o7sPdPfBpI/tHHe/GJgL/HMwW6faZwB3XwesMrNjglGTgCV04mNN+tLSRDMrCv6tt+5zpz7WGfZ0bGcDnw2eZpoI1GVcitqnLv9NajP7JOnr1K3NgXyng0vKCTP7CPBX4DXevx5/E+n7EI8Cg4B3gQsOQrMmB52ZnQZ8zd3PMrOjSJ9RlAGvAp9x96aOrK+9mdmxpG/M5wErgOmk/yDstMfazL4FTCP9xN6rwBWkr7d3qmNtZr8CTiPdrPd60p2rPU7IsQ3C8sekL7ftAKa7e1XW2+rqASEiIuG6+iUmERHZAwWEiIiEUkCIiEgoBYSIiIRSQIiISCgFhMh+MLOkmS3MeLVbg3dmNjizhU6RjpazLkdFOqkGdz+2o4sQORh0BiHSDsxspZl9z8xeM7NXzOzDwfjBZjYnaIv/OTMbFIzvY2aPmdk/gtdJwaqiZvbToF+DP5tZYYftlHR5CgiR/VO4yyWmaRnT6tx9NOlvrt4ZjLsbeMjdxwCPAHcF4+8C/uLuY0m3k7Q4GD8UuMfdRwJbgE/neH9E9kjfpBbZD2ZW7+4lIeNXAqe7+4qgUcR17t7LzDYC/dw9EYxf6+69zawGGJjZ7EPQDPszQacvmNm/A3F3vy33eyayO51BiLQf38P7/ZHZTlAS3SeUDqSAEGk/0zJ+vhi8f4F0S7IAF5NuMBHS3UL+K7T1md3jYBUpki39dSKyfwrNbGHG8FPu3vqoa6mZLSJ9FnBRMO4a0j27fZ10L2/Tg/FfAWaY2eWkzxT+lXRPaCKHDN2DEGkHwT2ISnff2NG1iLQXXWISEZFQOoMQEZFQOoMQEZFQCggREQmlgBARkVAKCBERCaWAEBGRUP8f5sVflRkh8zQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_list, label='accuracy')\n",
    "plt.plot(val_acc_list, label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.7, 1])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3dd3xV5f3A8c83d2UvCDMBgjIFAUUErahY955o3XVU66pa6/hZtWhrra1ardXiHqjgRkVpFRAXI2yQvRNWEiCM7Hu/vz/OCbkJgSSQm0Dyfb9e95V7njPuc3LgfvM833OeR1QVY4wxpq6imroCxhhjDi4WOIwxxtSLBQ5jjDH1YoHDGGNMvVjgMMYYUy/epq5AY2jdurV26dKlqathjDEHlRkzZuSpalr18hYROLp06UJWVlZTV8MYYw4qIrK6pnLrqjLGGFMvFjiMMcbUiwUOY4wx9dIichzGmJanrKyM7OxsiouLm7oqB7zo6GjS09Px+Xx12t4ChzGmWcrOziYhIYEuXbogIk1dnQOWqpKfn092djaZmZl12se6qowxzVJxcTGtWrWyoFELEaFVq1b1aplZ4DDGNFsWNOqmvr8nCxx78dHMbEZNrfE2ZmOMabEscOzF53PX8960tU1dDWPMQSo+Pr6pqxARFjj2wu+JoqQ82NTVMMaYA4oFjr0I+KIoKQ81dTWMMQc5VeWee+6hT58+9O3bl9GjRwOwfv16hg4dSv/+/enTpw/fffcdwWCQa665Zte2Tz/9dBPXfnd2O+5e+D1RlFrgMOag96fPFvDzum0NeszeHRJ5+OzD6rTtRx99xOzZs5kzZw55eXkcddRRDB06lHfeeYdTTz2V//u//yMYDFJYWMjs2bPJyclh/vz5AGzdurVB690QrMWxF9biMMY0hO+//57LLrsMj8dD27ZtOf7445k+fTpHHXUUr732Go888gjz5s0jISGBrl27smLFCm677Ta++uorEhMTm7r6u7EWx174PR5rcRjTDNS1ZdDYhg4dyuTJk/niiy+45ppruOuuu7jqqquYM2cO48eP58UXX2TMmDG8+uqrTV3VKqzFsRdOi8OS48aY/XPccccxevRogsEgubm5TJ48mUGDBrF69Wratm3LDTfcwPXXX8/MmTPJy8sjFApx4YUX8thjjzFz5symrv5urMWxF35PFGVBJRRSoqLsQSJjzL45//zz+emnn+jXrx8iwt/+9jfatWvHG2+8wZNPPonP5yM+Pp4333yTnJwcrr32WkIhp7fj8ccfb+La784Cx14EfE6DrDQYIjrK08S1McYcbHbs2AE4T2Y/+eSTPPnkk1XWX3311Vx99dW77XcgtjLCRbSrSkROE5HFIrJMRO6rYf1QEZkpIuUiclFY+YkiMjvsVSwi57nrXheRlWHr+keq/n6P8+uxBLkxxlSKWItDRDzA88DJQDYwXUTGqurPYZutAa4Bfh++r6pOBPq7x0kFlgH/DdvkHlX9IFJ1rxDwOa0MJ89Rt+GGjTGmuYtkV9UgYJmqrgAQkfeAc4FdgUNVV7nr9vYn/UXAl6paGLmq1izgtjjszipjjKkUya6qjkD4QE/Zbll9XQq8W63szyIyV0SeFpFATTuJyI0ikiUiWbm5ufvwsZU5DuuqMsaYSgf07bgi0h7oC4wPK74f6AkcBaQC99a0r6qOVNWBqjowLS1tnz7fby0OY4zZTSQDRw6QEbac7pbVxyXAx6paVlGgquvVUQK8htMlFhHW4jDGmN1FMnBMB7qJSKaI+HG6nMbW8xiXUa2bym2FIM7MI+cB8xugrjUKeJ3kuLU4jDGmUsQCh6qWA7fidDMtBMao6gIRGSEi5wCIyFEikg1cDPxHRBZU7C8iXXBaLN9WO/QoEZkHzANaA49F6hz83ooWhz09boyJvL3N37Fq1Sr69OnTiLXZs4g+AKiq44Bx1coeCns/HacLq6Z9V1FDMl1VhzVsLfcs4LUchzHGVGdPju9FZYvDAocxB7Uv74MN8xr2mO36wul/3esm9913HxkZGdxyyy0APPLII3i9XiZOnMiWLVsoKyvjscce49xzz63XRxcXF3PzzTeTlZWF1+vlqaee4sQTT2TBggVce+21lJaWEgqF+PDDD+nQoQOXXHIJ2dnZBINB/vjHPzJ8+PB9Pm2wwLFXluMwxuyP4cOH87vf/W5X4BgzZgzjx4/n9ttvJzExkby8PAYPHsw555yDk7atm+effx4RYd68eSxatIhTTjmFJUuW8OKLL3LHHXdw+eWXU1paSjAYZNy4cXTo0IEvvvgCgIKCgv0+Lwsce2E5DmOaiVpaBpEyYMAANm3axLp168jNzSUlJYV27dpx5513MnnyZKKiosjJyWHjxo20a9euzsf9/vvvue222wDo2bMnnTt3ZsmSJQwZMoQ///nPZGdnc8EFF9CtWzf69u3L3Xffzb333stZZ53Fcccdt9/ndUA/x9HUAtZVZYzZTxdffDEffPABo0ePZvjw4YwaNYrc3FxmzJjB7Nmzadu2LcXFxQ3yWb/61a8YO3YsMTExnHHGGUyYMIHu3bszc+ZM+vbty4MPPsiIESP2+3OsxbEXfkuOG2P20/Dhw7nhhhvIy8vj22+/ZcyYMbRp0wafz8fEiRNZvXp1vY953HHHMWrUKIYNG8aSJUtYs2YNPXr0YMWKFXTt2pXbb7+dNWvWMHfuXHr27ElqaipXXHEFycnJvPzyy/t9ThY49sJaHMaY/XXYYYexfft2OnbsSPv27bn88ss5++yz6du3LwMHDqRnz571PuZvf/tbbr75Zvr27YvX6+X1118nEAgwZswY3nrrLXw+H+3ateOBBx5g+vTp3HPPPURFReHz+XjhhRf2+5xEVff7IAe6gQMHalZWVr33U1Uy7x/H7Sd1466Tu0egZsaYSFm4cCG9evVq6mocNGr6fYnIDFUdWH1by3HshYjg99r0scYYE866qmoR8ERZjsMY02jmzZvHlVdeWaUsEAgwderUJqrR7ixw1CLgi7IchzEHKVWt1/MRB4K+ffsye/bsRv3M+qYsrKuqFn5rcRhzUIqOjiY/P7/eX4otjaqSn59PdHR0nfexFkctAj6PtTiMOQilp6eTnZ3Nvk7k1pJER0eTnl7jsIE1ssBRC6fFYclxYw42Pp+PzMzMpq5Gs2RdVbWwHIcxxlRlgaMWluMwxpiqLHDUwlocxhhTlQWOWliLwxhjqrLAUYuA12NPjhtjTJiIBg4ROU1EFovIMhG5r4b1Q0VkpoiUi8hF1dYFRWS2+xobVp4pIlPdY44WEX8kzyHgsxaHMcaEi1jgEBEP8DxwOtAbuExEelfbbA1wDfBODYcoUtX+7uucsPIngKdV9VBgC3Bdg1c+jN9jOQ5jjAkXyRbHIGCZqq5Q1VLgPaDKxLqqukpV5wJ1+mYWZ+yAYcAHbtEbwHkNV+XdWYvDGGOqimTg6AisDVvOdsvqKlpEskRkiohUBIdWwFZVLa/tmCJyo7t/1v48Oer32JPjxhgT7kB+cryzquaISFdggojMA+o8y7qqjgRGgjMfx75Wwrkd15LjxhhTIZItjhwgI2w53S2rE1XNcX+uACYBA4B8IFlEKgJevY65L/yeKMqCSihkA6UZYwxENnBMB7q5d0H5gUuBsbXsA4CIpIhIwH3fGjgW+FmdYS4nAhV3YF0NfNrgNQ8T8Lnzjgetu8oYYyCCgcPNQ9wKjAcWAmNUdYGIjBCRcwBE5CgRyQYuBv4jIgvc3XsBWSIyBydQ/FVVf3bX3QvcJSLLcHIer0TqHMBpcYDNO26MMRUimuNQ1XHAuGplD4W9n47T3VR9vx+Bvns45gqcO7YaRcDnAXDzHL7G+lhjjDlg2ZPjtQi4LQ67JdcYYxwWOGpRkeOwripjjHFY4KiF31ocxhhThQWOWliLwxhjqrLAUQu/x0mOW4vDGGMcFjhqUdnisKfHjTEGLHDUynIcxhhTlQWOWliOwxhjqrLAUQtrcRhjTFUWOGpR9clxY4wxFjhqYS0OY4ypygJHLSzHYYwxVVngqIWNjmuMMVVZ4KhFwGuBwxhjwlngqIWI4Pfa9LHGGFPBAkcdBDxRlhw3xhiXBY46CPiirKvKGGNcEQ0cInKaiCwWkWUicl8N64eKyEwRKReRi8LK+4vITyKyQETmisjwsHWvi8hKEZntvvpH8hzASZBbi8MYYxwRmzpWRDzA88DJQDYwXUTGhs0dDrAGuAb4fbXdC4GrVHWpiHQAZojIeFXd6q6/R1U/iFTdqwv4PNbiMMYYVyTnHB8ELHPnCEdE3gPOBXYFDlVd5a6r8q2sqkvC3q8TkU1AGrCVJuC0OCw5bowxENmuqo7A2rDlbLesXkRkEOAHlocV/9ntwnpaRAJ72O9GEckSkazc3Nz6fmwVluMwxphKB3RyXETaA28B16pqxTf3/UBP4CggFbi3pn1VdaSqDlTVgWlpaftVD8txGGNMpUgGjhwgI2w53S2rExFJBL4A/k9Vp1SUq+p6dZQAr+F0iUWUtTiMMaZSJAPHdKCbiGSKiB+4FBhblx3d7T8G3qyeBHdbIYiIAOcB8xu01jWwFocxxlSKWOBQ1XLgVmA8sBAYo6oLRGSEiJwDICJHiUg2cDHwHxFZ4O5+CTAUuKaG225Hicg8YB7QGngsUudQIeD12JPjxhjjiuRdVajqOGBctbKHwt5Px+nCqr7f28DbezjmsAauZq38XmtxGGNMhQM6OX6gCHgtx2GMMRUscNSBtTiMMaaSBY46cHIcFjiMMQYscNSJtTiMMaaSBY46CHijKA2GCIW0qatijDFNzgJHHfjdWQBLg9bqMMYYCxx1YNPHGmNMJQscdVAZOOwhQGOMscBRBwGvB8AS5MYYgwWOOgn4rKvKGGMqWOCoA7/HTY5b4DDGGAscdWEtDmOMqWSBow78HstxGGNMBQscdVDZ4rC7qowxxgJHHViOwxhjKlngqAPLcRhjTCULHHVgLQ5jjKlkgaMOAj4nOW45DmOMiXDgEJHTRGSxiCwTkftqWD9URGaKSLmIXFRt3dUistR9XR1WfqSIzHOP+ayISCTPAazFYYwx4SIWOETEAzwPnA70Bi4Tkd7VNlsDXAO8U23fVOBh4GhgEPCwiKS4q18AbgC6ua/TInQKu1iOwxhjKtUpcIhInIhEue+7i8g5IuKrZbdBwDJVXaGqpcB7wLnhG6jqKlWdC1T/Rj4V+J+qblbVLcD/gNNEpD2QqKpTVFWBN4Hz6nIO+6OixWGBwxhj6t7imAxEi0hH4L/AlcDrtezTEVgbtpztltXFnvbt6L6v9ZgicqOIZIlIVm5ubh0/tmY2rLoxxlSqa+AQVS0ELgD+raoXA4dFrlr7T1VHqupAVR2Ylpa2X8cSEfwemz7WGGOgHoFDRIYAlwNfuGWeWvbJATLCltPdsrrY07457vt9OeZ+CXij7K4qY4yh7oHjd8D9wMequkBEugITa9lnOtBNRDJFxA9cCoyt4+eNB04RkRQ3KX4KMF5V1wPbRGSwezfVVcCndTzmfvF7rcVhjDEA3rpspKrfAt8CuEnyPFW9vZZ9ykXkVpwg4AFedYPOCCBLVceKyFHAx0AKcLaI/ElVD1PVzSLyKE7wARihqpvd97/Fya/EAF+6r4hzWhwWOIwxpk6BQ0TeAW4Cgjhf5oki8k9VfXJv+6nqOGBctbKHwt5Pp2rXU/h2rwKv1lCeBfSpS70bkrU4jDHGUdeuqt6qug3n1tcvgUycO6tajIDXYzkOY4yh7oHD5z63cR4wVlXLAI1ctQ48fuuqMsYYoO6B4z/AKiAOmCwinYFtkarUgShgXVXGGAPUMXCo6rOq2lFVz1DHauDECNftgBLwWYvDGGOg7kOOJInIUxVPYovIP3BaHy1GlQcAt66BZd80bYWMMaaJ1LWr6lVgO3CJ+9oGvBapSh2IqiTHf/wXjLl67zsYY0wzVafbcYFDVPXCsOU/icjsSFToQFUlOb5zE5Ruh2AZeGob69EYY5qXurY4ikTkFxULInIsUBSZKh2YWsX7yd1egqpCYb5TWNyi7g8wxhig7i2Om4A3RSTJXd4CtKi+moyUWApLg2wpLCO10H2IvXgrxLVq2ooZY0wjq+tdVXNUtR9wOHC4qg4AhkW0ZgeYjNRYANZuLoSdeU5hibU4jDEtT71mAFTVbe4T5AB3RaA+B6z0lBgA1m7eGdZVVdCENTLGmKaxP1PHRnyu7wNJRYtjQ24ehMqcQgscxpgWaH8CR4saciQ+4CUl1seWvPWVhZYcN8a0QHtNjovIdmoOEIIzrHmLkpEay87NyyoLrMVhjGmB9ho4VDWhsSpyMMhIiaVkbV5lgSXHjTEt0P50VbU46akxhHaEBQ5rcRhjWqC6PsdhcFocwYqbyqKTLXAYY1qkiLY4ROQ0EVksIstE5L4a1gdEZLS7fqqIdHHLLxeR2WGvkIj0d9dNco9Zsa5NJM8hXEZqLK1kG6EoPyR2tOS4MaZFiljgEBEP8DxwOtAbuExEelfb7Dpgi6oeCjwNPAGgqqNUtb+q9seZaXClqoaPjXV5xXpV3RSpc6guPSWGFLZT4k+G6CRrcRhjWqRItjgGActUdYWqlgLvAedW2+Zc4A33/QfASSJS/fmQy9x9m1zH5BhSZTs7opKcwFFigcMY0/JEMnB0BNaGLWe7ZTVuo6rlQAFQffCn4cC71cpec7up/lhDoAFARG6smD8kNzd3384gdzFkZ+1ajPZ5aOvdyRZJtBaHMabFOqDvqhKRo4FCVZ0fVny5qvYFjnNfV9a0r6qOVNWBqjowLS1t3yow/gH44u4qRa2jtpMXjIfoRMtxGGNapEgGjhwgI2w53S2rcRsR8QJJQH7Y+kup1tpQ1Rz353bgHZwuschI6QJbVlYpSmY768ti3a6qbRCy6WSNMS1LJAPHdKCbiGSKiB8nCIytts1YKodnvwiYoKoKICJROLMN7spviIhXRFq7733AWcB8IiUl0+mOqhhGPVhObHA72SUxBP0JoCEo3RGxjzfGmANRxJ7jUNVyEbkVGA94gFdVdYGIjACyVHUs8ArwlogsAzbjBJcKQ4G1qroirCwAjHeDhgf4GngpUudAaqbzc8tKiE2F4q0ISp4msjUU6yRjSrY53VbGGNNCRPQBQFUdB4yrVvZQ2Pti4OI97DsJGFytbCdwZINXdE9S3MCxeSV0PHLXPBxbNIHcsmgncBQXQFJ6o1XJGGOa2gGdHG9yKZ2dn1tWOT/deTg2k8D6YneucUuQG2NaGAsce+OPg/i2lQlyN3AUSCLZxX6nzG7JNca0MBY4apOSCZtXOe/dwOFLSGPVDreXz0bINca0MBY4apOaGdbicHIcialtWL7d45RZi8MY08JY4KhNSiZsWwdlxc5tuf4E2qcms3iL+8B68damrZ8xxjQyCxy1SekCKGxd7XRVxabSq30C63cq6om25LgxpsWxwFGbXc9yrHICR1xrBnZJBaDEG29dVcaYFscCR23Cn+XYmQexrejZLoFYv4ftxFpy3BjT4ljgqE1ca/DHOwnyws0Q2wqvJ4oBnZLJL4+xFocxpsWxwFEbEfeW3JVujsMZ9X1g51Q2lgUIFlpy3BjTsljgqIuUzpC7EMp2VgaOLils11hKdlrgMMa0LBY46iI1E7aucd67gWNApxS2EYsWHYCBY/0cmDumqWthjGmmLHDURUWCHHYFjviAF39sMr6yA3BY9akjYdw9TV0LY0wzZYGjLlJ3DxwAyamt8VNKeUlRE1RqL4q3Ond7OVObGGNMg7LAURcpXSrfx7Xe9bZNm7YALFmzrpErVIuSbTbJlDEmYixw1EVSBog7NlVYiyOjfTsAFq5c6xSUFcOyb5x8SFP+tV9xi7A91W6MiYCITuTUbHh8kJzhBITo5F3FKalpACxf606lnvUqjL/feR+TCp2GwIUvgz+2ceu7K3AUQFLHxv1sY0yzZy2OukrJdIJBVNivLOBMGbtm3QaCIYXVPzitkzP/4QSNxV/A+tmNX9eKloY91W6MiYCIBg4ROU1EFovIMhG5r4b1AREZ7a6fKiJd3PIuIlIkIrPd14th+xwpIvPcfZ4VEYnkOezS5wLoe1HVsugkAEJFW3n6v4thzRTo8gs46no4eYSzTcXsgY1FtWqLwxhjGljEAoeIeIDngdOB3sBlItK72mbXAVtU9VDgaeCJsHXLVbW/+7oprPwF4Aagm/s6LVLnUMURV8HpT1QtcwPHSZnRfP7t9858HRlHO+uSO4FEOU+cN6ayQtCg895yHMaYCIhki2MQsExVV6hqKfAecG61bc4F3nDffwCctLcWhIi0BxJVdYqqKvAmcF7DV72Oop2uqnN6xnFeqpMgz07o56zz+iExvXISqMYS3sqwuUKMMREQycDREVgbtpztltW4jaqWAwVAxW1LmSIyS0S+FZHjwrbPruWYAIjIjSKSJSJZubm5+3cme+KPB4nCV7aD67tsYhtx3DBuG2XBkLM+pXPjtzjCA4flOIwxEXCgJsfXA51UdQBwF/COiCTW5wCqOlJVB6rqwLS0tIhUEhEnQV5cQPzGGRS1PZKFG3cyeYkbqFIzGz/HEd49ZTkOY0wERDJw5AAZYcvpblmN24iIF0gC8lW1RFXzAVR1BrAc6O5un17LMRtXdJITHPIW07r3UFLj/Hw0y61SSqaT9yjZ3nj1qdJVZS0OY0zDi2TgmA50E5FMEfEDlwJjq20zFrjafX8RMEFVVUTS3OQ6ItIVJwm+QlXXA9tEZLCbC7kK+DSC51C76CRY+R0Ans5DOPvw9nz980a2FZdVDlXSmN1VFYFDoqzFYYyJiIgFDjdncSswHlgIjFHVBSIyQkTOcTd7BWglIstwuqQqbtkdCswVkdk4SfObVHWzu+63wMvAMpyWyJeROoc6iU6C8iKI8kKHIzhvQEdKykN8NX9D5VAljdldVeIGi4QOluMwxkRERJ8cV9VxwLhqZQ+FvS8GLq5hvw+BD/dwzCygT8PWdD+4t+TSvh/4Y+mfEUOXVrF8MiuHSw7r6axrzDurKloZyRnW4jDGRMSBmhw/eFQEjozBAIgI5w3oyE8r8llfGoCYlEbuqtoGHj/Et7EchzEmIixw7C932BE6Hb2r6PwBHVGFT2evcxLkjdlVVVzgBLPoJGtxGGMiwgLH/opNdX66LQ6Azq3iOKJTMp/MynHyHI3dVRVIdF6W4zDGRIAFjv11xFUw/G1IaFul+LwBHVm0YTubAx1h61oIljVOfUq2uS2OZGf4kcb6XGNMi2GBY38ltINeZ+9W/ItDnQmflpalOWNHFazdbZuI2NVV5XahWZ7DGNPALHBESGbrOFJifcza7ibPGyvPUVzgBI2KpL2NV2WMaWAWOCJERDiiUwqTcuOcgsa6s6rY7aqqSNpbnsMY08AscETQEZ1TmJofjXoCjZcgr0iOW1eVMSZCLHBE0BGdUlCiKIzr2DhdVeWlzlPs0clhXVV2S64xpmFZ4IigfhlJeKKEjVHtYfOqyH9gRbeUdVUZYyLIAkcExfq99GyXwNLy1k5XlWpkP7CidVElOW4tDmNMw7LAEWFHdk5h5rZkKN0BhfkUlQZ56n9L2LyztOE/bFfgSIJAgltmLQ5jTMOywBFhR3RKYWm5O5HU5hU8N2Epz36zlJGTV+z/wUNB51UhPHBEeXZNMmWMMQ3JAkeEHdk5heXaAYBNK+bw0ncr8EYJ701fQ1FpsJa9a/HRjfDBtZXLFUGiIr9hw44YYyLAAkeEpafEUBSbTpn4mTH9R6J9Hv556QC2Fpbx6ez9nLxwzU+QnVW5HJ4cr/hpLQ5jTAOzwBFhIsKALq1YHOpIXMFS7j65O2f0bUev9om8/uMqdF8T5iXbYVuO8yorcsrCu6rASZJb4DDGNDALHI3giE4pLA51pJd3HVcM7oyIcM0xnVm0YTtTV26u/QA1yVta+b7iGZHibYCAP95ZthaHMSYCIho4ROQ0EVksIstE5L4a1gdEZLS7fqqIdHHLTxaRGSIyz/05LGyfSe4xZ7uvNpE8h4ZwQo82ZHs7k6b5eEud7qRz+3ckOdbH6z+sqtxwzVSnJVEX4YFjs5torxinKsq9rJbjMMZEQMQCh4h4gOeB04HewGUi0rvaZtcBW1T1UOBp4Am3PA84W1X7AlcDb1Xb73JV7e++NkXqHBpKj3YJ3H6pO4Ju7iIAon0eLhvUif/+vIE1+YWwaRG8egp894+6HTRvMSDO+/DAEUiq3Ma6qowxERDJFscgYJmqrlDVUuA94Nxq25wLvOG+/wA4SUREVWep6jq3fAEQIyKBCNY14qRNL+fNpoW7yq4c3JmA18NlL01h88RnncKFn9ftgHlLoNWh7tS0buComIujQnSS030V6QcPjTEtSiQDR0cgfBKKbLesxm1UtRwoAFpV2+ZCYKaqloSVveZ2U/1RRKSmDxeRG0UkS0SycnNz9+c8GkZSJ/DF7WpxAHRIjmHMb4YQH9pGzM/vU+pPgvylVbuh9iRvKbTuDqldq3VVhQWOQKIzF0jpzgY+GWNMS3ZAJ8dF5DCc7qvfhBVf7nZhHee+rqxpX1UdqaoDVXVgWlpa5Ctbm6goSOtRpcUB0Dc9iQ+PXkqMlPKbHTcCUDTvs70fK1gO+cuhdbcaAkdi5XYVQcTyHMaYBhTJwJEDZIQtp7tlNW4jIl4gCch3l9OBj4GrVHV5xQ6qmuP+3A68g9MldnBo06tKiwOAYDnxc14n1Pk4DjnmAhaEOrP429F8Mitnz7fqblkFoTInEKV2hYJsKC+pnIujwq6h1S3PYYxpOJEMHNOBbiKSKSJ+4FJgbLVtxuIkvwEuAiaoqopIMvAFcJ+q/lCxsYh4RaS1+94HnAXMj+A5NKy0nrBjIxSG3YK76DPYlk3UkJt58KzepA08n8NZzKOjv+XhsQuq7K6qvDBpOdOm/+QUVHRVaQi2rtm9q2rXQIfW4jDGNJyIBQ43Z3ErMB5YCIxR1QUiMkJEznE3ewVoJSLLgLuAilt2bwUOBR6qdtttABgvInOB2TgtlpcidQ4Nro17U1l4d9WUFyGlC3Q/zdnkqAuIQnm4x1re/Gk1o6au3rXpcxOW8a0PjrkAABy+SURBVMRXi/h+yo9OQUVXFUD+MqdLKhDWVRWwEXKNMQ3PG8mDq+o4YFy1sofC3hcDF9ew32PAY3s47JENWcdG1aan8zN3IXQ5FlZ+B2unwKmPO4MSArQ7HJIyODswi496nMjDny6gW5sEVubt4Kn/LeH47ml0WpnNjujWxEcnVQaODfMArbnFYTkOY0wDOqCT481OYkenRbBpkTOq7fgHIDEdBoYNVCgCPU5HVkzinxf2oFOrWG54M4sHPp7P0O5pvHz1QI6My2V+aTtnaPbYVs4x181y9m+KHMfEx2HZN5H9DGPMAcMCR2MScRLauYtgznuwYS788hHwxVTdrsfpUF5E0rrveemqgYRU6dU+gRcuPwJflNAplMPSUHv+M3m5c8zUTFg329k3/K6qQCMEjh2b4Nu/wo/PRu4zjDEHFAscjS2tJ2ycD9+MgI4Doe9Fu2/T+RcQ2xq+foRD4kqZ+PsT+OCmY4gLeGHHRjyl24jp0Is3f1xN7vYSp7tqu/u8ZHiLwxcDUb7IdlUtn+j8XP1T5WCLxphmzQJHY2vTG4q2wI4NcOpfnBZDdV4/XPKGc9vte7+idUCJ9rk5kLwlABx79BBKyoMMH/kTby/17Nq1xJtQeRyRyA87snyC8zNY4gzzboxp9ixwNLaKBPlh50Ono/e8XZdfwPn/cb6MP7oBQiGnPHcxAO0P7c9tw7qREO0jlJy5a7fnf6o2dFfFsCOREAo5gaPHGU7LZsWkyHyOMeaAYoGjsXU6Bgbf4txJVZs+FzitkoVj4a3zYMl4Jz/ij4eE9tx5cnc+veVYrjpz1+DBvDVrK1/MXb9rudgTT17epn2f92NvNi2AnZug51mQcXRlt5UxplmL6O24pga+aDjtL3XffsgtIFHw/TPwziVOWYcBVbu4Km7JBbqmd+C+D+eSEO3lo5nZXLQxSDQbeOTdWTx+QV8Son0NdCJUdlMdMszJsUx4DHbmQVzrhvsMY8wBx1ocB4PBN8Od8+Hi150v6cMvrbo+vi34YsEXyzO/OgoErnp1GuMXbKR1qzQy48v5cv4GzvnXD0xcvIm3flrFre/M5MIXfuT9rLWUB0P7Vq9l3zg5m8T20NVt9Vh3lTHNngWOg4XH5+RFrvwYBt9UdZ2I0+qITiIjNZaRVw7kjpO68d29J9KzSzqtPMW8c/3R7Cwp59rXpvPQp/NIWT6W6zY/zUMfTOOkp77lgxnZuwWQ7C2FPPHVIpZsrGFyqdJCJ/9yiBswOvR38il7ChzlpVBWvG/nvm4WvHIqbN+4b/sbYxqUBY7mom0fSOwAwJBDWnHnyd1pHR9whh0pzOPoDe/y9cUxjDmllEWd/86jwac5o+y/fDJ4GfEBL79/fw7D/vEt705bw7biMp75egkn/eNbXpi0nHP/9QMfzsiu+nmrf4BgaWXgiPJA5lAncNSUTxlzJbx2Wv3nBlGFL+9znrCf8u/6/16MaWw7NsG/BkH2jKauScRY4GguzvgbXPbe7uWHngTx7eC//0fiO2cwaPI1BAo3wXkvQOdj6bH8dT6/+SheumogybE+7v9oHgNG/I9nvl7KKb1a8815ypEdY7j7/Tnc+8FcthWXOcddPgG80dD5GEIhdZLvXU+EgrXOkO/h1s2CJV85P5fX8wnzJV85QSMuDbJeq/vUusY0lSVfOTN0znm3qWsSMZYcby7CH/wLd+hJcOc82L4BsqdD0VbocyH4Y53cyNsXIHNHc/KRV/PLXm34bmkeXy3YwCWdC+k/8wH4ahpvdj+dp0/4I89NWsXYOes49/C2PJL9FdtTj+SR9xcycdEmWscHuLJHF24AWDERWh9aWYfvnnJaPr4Y+PE5OPSXdTunUBC+/hOkHgLnvwivnAwz3oBjbt3f35YxkVMx/M6S8XDGkzU/q3WQs8DRUiS0g15nVy07ZBi07w/fPw39L0c8XoYekszQDa/DF39zbvs94mqiZr7B3Ue25dRb/8SYHxdx4vy7iJYVPFh2MlM353NOvw7kbC3i8Sl5nORrR9S4f/CHH9JJSGlNv5hN3LbwM1b0/A1xiSm0m/Y4wZzZFLfuw5zsrcxas5WVeTspKgtSXBqkdXyAB87oRVKszxmWJXchXPwGZAyCLsfBlBfg6N84OZ9IKS91HmgMJBAMKUVlQeIDB9l/lbxlsHgcHHNbs/ziOmCFgk53bSAJCtY4I2G37d3UtWpwB9n/BtOgRGDo72H0FfDzJ9D2MPj4Jlg/20nEn/4kxKc5Ayl+/xR9/PH02TwZjZrPrD5/5ML+1/JEZiqeKOeLKXd7CTMm/4VfZt3IIyVPcM+Whzh71UiK1cfFs/tTjocfA9F8/eID3FV+CyE33dE+KZoYv4dor4fJS3OZuWYLr13Zl/SJfyHU4Qheze/L+Bd/5Nb0Szl+1S0w/yPoN7zKqfywLI/7P5rHhUekc9uwQ4mK2scvy9JCeP1M2L6e0l9P4LqP1jJ77VZGXjmQIYdUn9XYtX2Dc7t0yTYIlUN0Mpz4AMQk7/Fjpq/aTK/2iZELSF/dC8u+huQM51qaxrFuFhRvhVP+DP/9P6fbqhkGDonIg2EHmIEDB2pWVlZTV+PAFArBvwc7/9iLtkAgAc56GnqfW7mNKnxys9Nn6493bgvudvKejzn7XfjkJuh1DiweR8mAX7NkwIOsLygifdpj9Fz9Dq8M/IRDu/VkQEYyybF+Z79gGQu//4QFE9/hRGbQigL+EPcoY/IPoX1SNOsLipgYez+tE6KJvm0KPq8HVeXNn1Yz4vOfSYj2srWwjFN6tea5jEkE2veGHmc60/buxeadpYyashq/R7h+06N4fv4U9QZY4evOqVt+T1pSPPk7SnlqeD/OOrxD1Z1V4Z3hTu4mvh2FQSF6Zw5be19B6iXP1fDrVv48biGvfL+Sw9OTeOvXRzutK3Bmcfzsd86IAkdeU/u125N1s2Hk8RDldUZkvnU6eAP7frz62r7RCaBJHfe8zeaVsHYqHD68ebWIJj0Bkx6HP6xwHtr1xcKvv2rqWu0zEZmhqgOrl1uLo6WLioLj/wAfXud80Z/5lNPKCCcC5zznjOzb7dTa/4LqfxnkL4Xv/gFRXgLH3U7f5CT6pidBx3vhn+9wQ3A0dHoMYvxO837e+zDpcXptWUV3XzwTg/15p3gwS2L68NJVh/HLXm0Yv2AjYz47j3sLnuXBEfezuvOFxPo9jF+wkV/2asszl/bn/ay1FH71CIGVnwCwMeYQJrS5mh/8x5C/M8iWwlJaxfvpl57M4enJZK3azKipaygqC3KH50M8vk/IPup+Zm2J4exlD/H+IV+Refk/ueHNLG57dxZrNhdy7TGZxPjd8cEWj4Ol4wn+8lGe3H4KL367nD/5XueKn98m5+df0bH3kF2/lpLyIHeNmcMXc9dz2mHtmLBoE5e/MoW3rzua5BgffHqL83uY8y7ZJTG8sLE3PdslcOWQLrVexuKyIKvzCwl4o+jy/VPOyMjnPAvvXwPTXtqVFyoLhigoKnPuuNuL0vIQfu8+3DuzdS28fJITOG6cBMmddt+mZAeMusiZfMwbaJwWUXkJIM44cJG0/BvnAd3YVGdytslPOjN+xqbufb/SQud3EeXZ+3YHCGtxGMfWNZCU0XB//YVCTlM9rjUcd3fVdWNvg5lvAgLtD3dG1c1bAu36wvH3QrdT2FSkTFqcyzn9OlQO8AiUlZVS8NI5JOXO4K64vzJ+SwduGJrJ3Sf3cLqnFn8J717KZ1HDmFTam1s8H9NVcigggTnRA1mSMJjCwh1kbJvNQFmEV4Jsj8ukXXpnEpd8xBdRJ3Jr0fWoCqM6fsSx+R/Aha9Q3PN87hw9my/nbyAh2st5/TtyWo9EjvjsNEqiYrg14Z98v7KAXx3diasHJJP2+jGsk3a0vuNbWidE8+PyfJ6bsJTpq7bwwBk9ueG4rkxanMtv3ppBt7bxPNPmC7oteoF5h95E9OpJpJeu4LKyPzI7dAg3HJfJ/af3IipKKC4L8vqPq5i+cjM7S8vZWRIkb0cJ6wucZ2QOicrha/8fCB17J56TH4a3LyS4djoj+33AdzkhZq3ZSlFZkGuP7cJ9p/ck4HV+t0WlQT6fu45pKzezc+VUfrfjGaYln0H38+5nUNc9dNFVV1yAvnIqWpBNUGGTpx1XhEYQiI3n2csG0L2tOwDnp7egs0axI6YjcVJM1C3TIK4Vqsq4eRv4bM46fnviIRzexuckmrufxqqtZbw7fQ3tE6Ppl5FMr/aJlf8u1k5zpk9u3X3XF/SyTdv5eFYOgzLiOH7LxzD5786X8pHXwFHXQVL6btWfsiKfxRu2c1KvNqSnxNZ6ujtLypmfU8CgzFRExLnx5G9d2THodh7afh5XddpM/6/OhwtegsOdUR+2FpaSGO2r2pW6M4/gi0PRVt3wXvXRARU89tTisMBhGl+wHLKnwcrJziyIZYVw7B1Oi6eWbiUAdubDyBNAQ4RumEhUQhunPH85jDwRUrvAr//rDO8SCsKiL2DR506ff2E+ABqXxta0gfij44jbvtJJJnc6mh3nvc5TE1ZTVFbOo2d1x/vWuZCTBSfchx57J1NXFzB6+lrGzVvPbbzLrd5PubjkIeZ7D2PEuYdx8cAMANZOeJmMyXfzZ++tfKrH0b1oNsP8C+hx7Pkce/IFu05l0qKNfDPqbzzqeZl3y0/k/vLr6Z1YwntRDxIfVcbotnfx0+Icjsvw0TtVmbVkNVElBaTGeFBfDCFvLDviOpGfeTbpbVvTYeJdHLblG65PfZVLjj+CaVN/YMS6G3kreAofpv2WIzPTKCkP8e60NfTpmMhfLzic75bm8fJ3K8jfWcpZMfP5B08RJYovVMKo8pP4qvPdZLZJoqCojG1FZRSXhSgPhSgNOt8dUQJ+gvwh/0EOL5/P1WX34qeMV/1/Jyv+RG4p/i2FpUH+cUk/Tij/gehPruP58nMZGxzC54EHyW5/Clz4Mn/6bAGTFufijRIGsIj/JLxMakkOaxOP4ML8m8kLxe3Ki3mihLQ4P7d6P+KKolG7fp+FvlRW0YEFRamsJ5XzPT+QIbnQ7RTw+GHxOBRhS49LSD7v70RFx7OtuIy/fTabXnMep0fUWh4uuwZfen9O6tmGjNRYDg2tpF3xCqTP+cTFxpK7vYQ3flzF6Ky1bC8u58y+7fn7xf2IWfY5jLmKWwJ/5ouCTIQQc+NvJ6b7Caw58Tmen7icT2bncGTnFJ69dADtkqIhFGLDi+fQeuMPeCXElPTr6PWrJ0iK9bG+oIgpK/KJ83s5qVfbXblEVeWbhZtYsmk7Q7q24vD05F3rwOkOLSwLUrR5Hd4pzxF3xmP4A/vWVdkkgUNETgP+CXiAl1X1r9XWB4A3caaDzQeGq+oqd939wHVAELhdVcfX5Zg1scDRDK2bDa+eCh2PdG4v3roGFn4GRZvhxm8hpfPu+4RCzuRZvlhnvva6tK6KtsLnd8KCjyBjsDPoZPEWitYtJDDpTxQccg5FZz5Pq3j/rr/eKz5r2wu/hNxFqCdAUnBz5bouxzmtsLylMON12LSAHRnHs/HMN/D7A7RPisa7ealz+3G1IfFL8CPRifh9fijb6XRxhMqchHz/X8G0kazuehnnrTiHLYVOl9Rrrd+m74aPnQP4EyChLQs7/YorZvUiv9j5/398t9Y8nDGbzJ/uR9oeBpe/T9mPL+D76Rl+kgH8Sy9mZ0x7gjGtiPb78Hmi8HqiiA4V0rdwGsfv/JLDS2byWeaDbO1xCb3aJTBg9at4Jj5KYZ/LeWNVMks2hxjhf4OloQ6MPeIVTumbTvbHD3PJjre5rvRuZnv78eCQaE7X7/BPe56cUCveDx3PLZ5P2eZvQ9TlYyhNOYQ5awtYkLOVAUufZVjeKCYETmJc8Ghal6wmU3Po6c/lUO9G4krzWOPryv07hzPwxAs4vkcaY/73I91Xvsk1nvGslI68kT6CeZtKGVH8V/pGrSIYSEZKtjMm+iJeLxjArd5POMszBYCFoU7cVXYzC7Uznijh9D7t6Nwqln9PWk7v9om8kvo2Ccs+ZSiv8u+rjmb8go30mHY/p3umM7DkBaK8fs7o256v5m8g2ufhrxf0Jfj9Pzl9/b95OfEWerOcwQXjuZn7WRw/iFX5hbuue9e0OH43pBVtPdt4Zuo2floXBJx/vykxXvp0SCS/sJxN20vYvLOE3qxgpP8pktnJ5ks+If2wY2r/t16DRg8cIuIBlgAnA9nAdOAyVf05bJvfAoer6k0icilwvqoOF5HewLvAIKAD8DXQ3d1tr8esiQWOZqoiCQ/OsO4pXeDMv0PXExr2c1Rh7hgY9/uqk2KlZMJ1/4X4NjXvt2EejLoEOh7hdFVkHu/cYPDdU86owuD0hx95rZMk9kVX3X/7RtiyEmJSmLC6lJ0Sx5kDMqt2c6jCmikw5XmnZSUeuGM2uVFp/Lx+G4O7phIIlTifuzPPCUQ5M2DtFMqTM/k6+RKOjN1IWs43zsObXU+A4W87N0mA89zM53eCBp1lj98JUoF4JwDnLXFGEIh1uySH/LZq3T69BWZXtgh2SBwrLviSw/v2czYpL2HHc78gdtsKPFpeue8RVzGtx+95e+ZmbuqaR+9vb3I+p8svnOF1dubC3NEw8Ndwxj8gKgpVZUdJOfEBr9N1VFZEmfi5/+P5fOCOfJAU4+PqIZ0ZpHPoP+0ePEFnmzgveC56CToNhq8egDnvABDyxbG2x7WsC3Sl37y/ECjbysKOF9I1IUTslsWwYyPr047lgRV9eJR/szSqK+1u/JBe7Z3ZNxdPeocek25mYcowMjukEe2Bzf4OPL0wkVVbSnjV9yTLU4dy6C0f4g2VUPziCZQXbODZNo/Sv52fw5OKKM2eBSsn0zW4atevpzwqGolJJFSyE095ISUSzZzYwSxt/Uta+co4ZcXjlPhTmT7keY44eiiJ+zi4aVMEjiHAI6p6qrt8P4CqPh62zXh3m59ExAtsANKA+8K3rdjO3W2vx6yJBY5mbMtq5+6hhHaR7xveuhZWfe+0ZlIPcQLGvuSESnfCws+dmw069G+4+m1Z5bSQajumqvNw2tePOM/JeKOdp/57nQV9L9k9gbxllfM8QkG28yre6pxD6U7nS7znWc5zNnv6/ZcVu3ftbXV+Z9UTxZsWwk/PO4n0VodAm8Mq563ZVYfV8M2fYNMi2LwCyotgyK1wymO1XgNV5dUfViHA8KMynJk0Abath49vdO4mvPgN57MrLPvaCfwDrqwc7blws/PHw/wPndEY2vZ2gujS/0GpM6LBpqF/oc2wWyqPU7LDaRnvzHOfPRLYlu3kZICi2I7E3PZj5a3beUudbtjSHZXH8EajGUezMuFINvvb0z+5BO/ODc4oCv548Mc5E8Mt/NxpcQN0PhYueXO/R6puisBxEXCaql7vLl8JHK2qt4ZtM9/dJttdXg4cjRMkpqjq2275K8CX7m57PWbYsW8EbgTo1KnTkatXr47IeRpz0AoFYf0cJ4D545q6NnWn6nxpRic23PHq8wdAWXHV1mFpoXN33ZqfYNiDEJOy9/1LdjjPe6yf44zs0KZX1fWbFjldqgntnVdyRt1upw6WwarvoCAH+l3aIA/JtrjbcVV1JDASnBZHE1fHmANPlMfpRjvYVEyJ3JDHq4/qXYr+WOh7kfOqi0A8ZB7nvGrSpufuLa668PgqBx2NsEgOcpgDZIQtp7tlNW7jdlUl4STJ97RvXY5pjDEmgiIZOKYD3UQkU0T8wKXA2GrbjAWudt9fBExQp+9sLHCpiAREJBPoBkyr4zGNMcZEUMS6qlS1XERuBcbj3Dr7qqouEJERQJaqjgVeAd4SkWXAZpxAgLvdGOBnoBy4RdW5raOmY0bqHIwxxuzOHgA0xhhToz0lx20iJ2OMMfVigcMYY0y9WOAwxhhTLxY4jDHG1EuLSI6LSC6wr4+OtwbyGrA6B4uWeN4t8ZyhZZ63nXPddFbVtOqFLSJw7A8RyarproLmriWed0s8Z2iZ523nvH+sq8oYY0y9WOAwxhhTLxY4ajeyqSvQRFriebfEc4aWed52zvvBchzGGGPqxVocxhhj6sUChzHGmHqxwLEXInKaiCwWkWUicl9T1ycSRCRDRCaKyM8iskBE7nDLU0XkfyKy1P1Zy7RmBx8R8YjILBH53F3OFJGp7vUe7Q7d36yISLKIfCAii0RkoYgMae7XWkTudP9tzxeRd0UkujleaxF5VUQ2uTOrVpTVeG3F8ax7/nNFpF4zelng2AMR8QDPA6cDvYHLRKR309YqIsqBu1W1NzAYuMU9z/uAb1S1G/CNu9zc3AEsDFt+AnhaVQ8FtgDXNUmtIuufwFeq2hPoh3P+zfZai0hH4HZgoKr2wZmO4VKa57V+HTitWtmeru3pOPMcdcOZYvuF+nyQBY49GwQsU9UVqloKvAec28R1anCqul5VZ7rvt+N8kXTEOdc33M3eAM5rmhpGhoikA2cCL7vLAgwDPnA3aY7nnAQMxZkHB1UtVdWtNPNrjTPvUIw7y2gssJ5meK1VdTLOvEbh9nRtzwXeVMcUIFlE2tf1syxw7FlHYG3YcrZb1myJSBdgADAVaKuq691VG4C2TVStSHkG+AMQcpdbAVtVtdxdbo7XOxPIBV5zu+heFpE4mvG1VtUc4O/AGpyAUQDMoPlf6wp7urb79f1mgcMAICLxwIfA71R1W/g6dzrfZnPftoicBWxS1RlNXZdG5gWOAF5Q1QHATqp1SzXDa52C89d1JtABiGP37pwWoSGvrQWOPcsBMsKW092yZkdEfDhBY5SqfuQWb6xouro/NzVV/SLgWOAcEVmF0wU5DKfvP9ntzoDmeb2zgWxVneouf4ATSJrztf4lsFJVc1W1DPgI5/o392tdYU/Xdr++3yxw7Nl0oJt794UfJ6E2tonr1ODcvv1XgIWq+lTYqrHA1e77q4FPG7tukaKq96tquqp2wbmuE1T1cmAicJG7WbM6ZwBV3QCsFZEebtFJwM8042uN00U1WERi3X/rFefcrK91mD1d27HAVe7dVYOBgrAurVrZk+N7ISJn4PSFe4BXVfXPTVylBicivwC+A+ZR2d//AE6eYwzQCWdI+ktUtXri7aAnIicAv1fVs0SkK04LJBWYBVyhqiVNWb+GJiL9cW4I8AMrgGtx/oBsttdaRP4EDMe5g3AWcD1Of36zutYi8i5wAs7w6RuBh4FPqOHaukH0XzjddoXAtaqaVefPssBhjDGmPqyryhhjTL1Y4DDGGFMvFjiMMcbUiwUOY4wx9WKBwxhjTL1Y4DCmAYhIUERmh70abKBAEekSPuKpMU3NW/smxpg6KFLV/k1dCWMag7U4jIkgEVklIn8TkXkiMk1EDnXLu4jIBHcuhG9EpJNb3lZEPhaROe7rGPdQHhF5yZ1X4r8iEtNkJ2VaPAscxjSMmGpdVcPD1hWoal+cJ3WfccueA95Q1cOBUcCzbvmzwLeq2g9nHKkFbnk34HlVPQzYClwY4fMxZo/syXFjGoCI7FDV+BrKVwHDVHWFO5jkBlVtJSJ5QHtVLXPL16tqaxHJBdLDh79wh7v/nzsZDyJyL+BT1ccif2bG7M5aHMZEnu7hfX2Ej6MUxPKTpglZ4DAm8oaH/fzJff8jzsi8AJfjDDQJzvSeN8OuOdGTGquSxtSV/dViTMOIEZHZYctfqWrFLbkpIjIXp9VwmVt2G85MfPfgzMp3rVt+BzBSRK7DaVncjDNznTEHDMtxGBNBbo5joKrmNXVdjGko1lVljDGmXqzFYYwxpl6sxWGMMaZeLHAYY4ypFwscxhhj6sUChzHGmHqxwGGMMaZe/h8p8/ocolzRLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list, label='loss')\n",
    "plt.plot(val_loss_list, label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.919358073094602e-05\n",
      "Best model is at 87th epoch\n"
     ]
    }
   ],
   "source": [
    "# Find model with the least validation loss\n",
    "index = np.argmin(val_loss_list)\n",
    "print(np.amin(val_loss_list))\n",
    "# Use that index to retrieve model weights\n",
    "model_wt = model_wt_dict[index]\n",
    "print('Best model is at {0}th epoch'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batchnorm1 (BatchNormalizati (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batchnorm2 (BatchNormalizati (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool2 (MaxPooling2D)      (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batchnorm3 (BatchNormalizati (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "maxpool3 (MaxPooling2D)      (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batchnorm4 (BatchNormalizati (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "maxpool4 (MaxPooling2D)      (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batchnorm5 (BatchNormalizati (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "maxpool5 (MaxPooling2D)      (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 50)                115250    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 190,896\n",
      "Trainable params: 190,448\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the model with weights\n",
    "model = model1(input_shape, \n",
    "                        kernel_list, \n",
    "                        learn_rate, \n",
    "                        output_shape)\n",
    "model.set_weights(model_wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 - 9s - loss: 8.9194e-05 - accuracy: 1.0000\n",
      "\n",
      "Train accuracy on whole dataset = 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy on the entire dataset\n",
    "train_wh_loss, train_wh_accuracy = model.evaluate(xtrain,  ytrain, verbose=2)\n",
    "\n",
    "print('\\nTrain accuracy on whole dataset = {0:.2f}%'.format(train_wh_accuracy*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if save path exists, if not then create one\n",
    "save_path = current_path + '/model' \n",
    "if not os.path.isdir(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(model, xtest, current_path):\n",
    "    \"\"\"\n",
    "    Create keggale submission csv. This also performs prediction on xtest\n",
    "    \n",
    "    Input Args:\n",
    "    model: Trained model\n",
    "    xtest: Numpy image of the test dataset\n",
    "    current_path: Path where submission file has to be created.\n",
    "                    It takes the previously stored sample submission file which you get \n",
    "                    from kaggle dataset\n",
    "    \"\"\"\n",
    "    # Predict test set labels\n",
    "    ypred = model.predict(xtest)\n",
    "    # Get labels for each row with maximum column value\n",
    "    ytest_label = np.argmax(ypred, axis=1)\n",
    "    # read the sample submission file \n",
    "    samp_submission_df = pd.read_csv(current_path+'/sample_submission.csv')\n",
    "    # add the the new ytest label \n",
    "    samp_submission_df.loc[:,'Label'] = ytest_label\n",
    "    # Save the file as submission \n",
    "    samp_submission_df.to_csv(current_path + '/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model if the accuracy on whole dataset is greater than 99.9 and also create test submission\n",
    "if round(train_wh_accuracy*100.0,3) > 99.9:\n",
    "    filename = save_path + '/model' + str(round(train_wh_accuracy*100.0,3))\n",
    "    model_json = model.to_json()\n",
    "    with open(filename + '.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    # Save weights of the model\n",
    "    model.save_weights(filename+'.h5')\n",
    "    # Create submission\n",
    "    create_submission(model, xtest, current_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
